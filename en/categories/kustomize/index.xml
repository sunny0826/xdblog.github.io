<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kustomize on GuoXD Blog</title>
    <link>https://guoxudong.io/en/categories/kustomize/</link>
    <description>Recent content in kustomize on GuoXD Blog</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&lt;a rel=&#39;license&#39; href=&#39;http://creativecommons.org/licenses/by-nc/4.0/&#39; target=&#39;_blank&#39;&gt;知识共享署名-非商业性使用 4.0 国际许可协议&lt;/a&gt;</copyright>
    <lastBuildDate>Thu, 04 Jul 2019 09:16:41 +0800</lastBuildDate>
    
	    <atom:link href="https://guoxudong.io/en/categories/kustomize/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>由一封邮件看 Mailing List 在开源项目中的重要性</title>
      <link>https://guoxudong.io/en/post/kubernetes-client-python/</link>
      <pubDate>Thu, 04 Jul 2019 09:16:41 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kubernetes-client-python/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;只要仔细找，想要的轮子总会有的。
&amp;mdash; 某不知名 DevOps 工程师&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;感谢 &lt;code&gt;kubernetes-dev&lt;/code&gt; 的 Mailing List ！早上在浏览邮件时发现了下面这封有趣的邮件：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wx3.sinaimg.cn/large/ad5fbf65gy1g4nkmrb8scj21780q0afv.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;接触 Kubernetes 也有不短的时间了，也见证了 Kubernetes 干掉 Swarm 和 Mesos 成为容器编排领域的事实标准的过程。在享受 Kubernetes 及其生态圈带来的便利的同时也在为 Kubernetes 及 CNCF 项目进行贡献。而使用 &lt;a href=&#34;https://github.com/kubernetes/kubectl&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;kubectl&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;https://github.com/rancher/rancher&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;rancher&lt;/code&gt;&lt;/a&gt; 甚至是 &lt;a href=&#34;https://github.com/IBM/kui&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;kui&lt;/code&gt;&lt;/a&gt; 这些 CLI 和 UI 工具对 Kubernetes 集群进行操作和观察。&lt;/p&gt;

&lt;p&gt;虽然上面这些工具为操作 Kubernetes 集群带来了极大的便利，但是归根到底还是一些开源项目，并不能满足我们的全部需求。所以我们只能根据我们自己的需求和 Kubernetes 的 api-server 进行定制，但是由于 Kubernetes 的 api-server 比较复杂，短时间内并不是那么好梳理的。&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-client-python&#34;&gt;kubernetes-client/python&lt;/h2&gt;

&lt;p&gt;由于我们自研的 DevOps 平台是使用 python 开发的，所以我也基于 python 语言开发了一套 Kubernetes Client ，但总的来说由于 Kubernetes 的功能实在太多，而我的开发实践并不是很多，开发出来的功能只是差强人意。&lt;/p&gt;

&lt;p&gt;而 &lt;a href=&#34;https://github.com/kubernetes-client/python&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;kubernetes-client/python&lt;/code&gt;&lt;/a&gt; 这个官方给出的轮子是真的香！&lt;/p&gt;

&lt;h3 id=&#34;安装方便&#34;&gt;安装方便&lt;/h3&gt;

&lt;p&gt;这个安装方式简单的令人发指，支持的 python 版本为 &lt;code&gt;2.7 | 3.4 | 3.5 | 3.6 | 3.7&lt;/code&gt; 并且和所有 python 依赖包一样，只需要使用 &lt;code&gt;pip&lt;/code&gt; 安装即可：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install kubernetes
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;简单示例&#34;&gt;简单示例&lt;/h3&gt;

&lt;p&gt;查看所有的 pod ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
#encoding: utf-8
#Author: guoxudong
from kubernetes import client, config

# Configs can be set in Configuration class directly or using helper utility
config.load_kube_config()

v1 = client.CoreV1Api()
print(&amp;quot;Listing pods with their IPs:&amp;quot;)
ret = v1.list_pod_for_all_namespaces(watch=False)
for i in ret.items:
    print(&amp;quot;%s\t%s\t%s&amp;quot; % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行查看结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Listing pods with their IPs:
172.22.1.126	kube-system	coredns-5975fdf55b-bqgkx
172.22.0.2	kube-system	coredns-5975fdf55b-vxbb4
10.16.16.13	kube-system	flexvolume-9ccf7
10.16.16.15	kube-system	flexvolume-h5xn2
10.16.16.14	kube-system	flexvolume-kvn5x
10.16.16.17	kube-system	flexvolume-mf4zv
10.16.16.14	kube-system	kube-proxy-worker-7lpfz
10.16.16.15	kube-system	kube-proxy-worker-9wd9s
10.16.16.17	kube-system	kube-proxy-worker-phbbj
10.16.16.13	kube-system	kube-proxy-worker-pst5d
172.22.1.9	kube-system	metrics-server-78b597d5bf-wdvqh
172.22.1.12	kube-system	nginx-ingress-controller-796ccc5d76-9jh5s
172.22.1.125	kube-system	nginx-ingress-controller-796ccc5d76-jwwwz
10.16.16.17	kube-system	terway-6mfs8
10.16.16.14	kube-system	terway-fz9ck
10.16.16.13	kube-system	terway-t9777
10.16.16.15	kube-system	terway-xbxlp
172.22.1.8	kube-system	tiller-deploy-5b5d8dd754-wpcrc
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;果然是一个好轮子，引入 kubeconfig 的方式及展示所有 namespace 的 pod 的方法封装的也十分简洁，是个非常漂亮的范例。建议可以看一下&lt;a href=&#34;https://github.com/kubernetes-client/python&#34; target=&#34;_blank&#34;&gt;源码&lt;/a&gt;，肯定会有收获的！&lt;/p&gt;

&lt;h3 id=&#34;支持版本&#34;&gt;支持版本&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;client-python&lt;/code&gt; 遵循 &lt;a href=&#34;https://semver.org/lang/zh-CN/&#34; target=&#34;_blank&#34;&gt;semver&lt;/a&gt; 规范，所以在 &lt;code&gt;client-python&lt;/code&gt; 的主要版本增加之前，代码将继续使用明确支持的 Kubernetes 集群版本。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Kubernetes 1.5&lt;/th&gt;
&lt;th&gt;Kubernetes 1.6&lt;/th&gt;
&lt;th&gt;Kubernetes 1.7&lt;/th&gt;
&lt;th&gt;Kubernetes 1.8&lt;/th&gt;
&lt;th&gt;Kubernetes 1.9&lt;/th&gt;
&lt;th&gt;Kubernetes 1.10&lt;/th&gt;
&lt;th&gt;Kubernetes 1.11&lt;/th&gt;
&lt;th&gt;Kubernetes 1.12&lt;/th&gt;
&lt;th&gt;Kubernetes 1.13&lt;/th&gt;
&lt;th&gt;Kubernetes 1.14&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;client-python 1.0&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 2.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 3.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 4.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 5.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 6.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 7.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 8.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 9.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 10.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python HEAD&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;mailing-list-的重要性&#34;&gt;Mailing List 的重要性&lt;/h2&gt;

&lt;p&gt;这次的收获很大程度得益于 &lt;code&gt;kubernetes-dev&lt;/code&gt; 的 Mailing List 也就是邮件列表。这种沟通方式在国内不是很流行，大家更喜欢使用 QQ 和微信这样的即时通讯软件进行交流，但是大多数著名开源项目都是主要使用 &lt;strong&gt;Mailing List&lt;/strong&gt; 进行交流，交流的数量甚至比在 GitHub issue 中还多，在与 Apache 、 CNCF 项目开源的贡献者和维护者交流中得知了使用 &lt;strong&gt;Mailing List&lt;/strong&gt; 主要考虑是一下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;这种异步的交流方式可以让更多关心该话题的开发人员一起加入到讨论中。&lt;/li&gt;
&lt;li&gt;mailing list 是永久保留的，如果你对某个话题感兴趣，可以随时回复邮件，关注这个话题的开发者都会收到邮件，无论这个话题是昨天提出的，还是去年提出的，有助于解决一些陈年老 BUG （俗称技术债）。&lt;/li&gt;
&lt;li&gt;即时通讯软件虽然很便利，但是问题很快会被评论顶掉，虽然诸如 slack 这样的工具解决了部分这方面的问题，但是还是不如 mailing list 好用。&lt;/li&gt;
&lt;li&gt;并不是所有地区的开发者都有高速的宽带，性能优秀的PC，在地球上很多地区还是只能使用拨号上网，网速只有几kb/s，他们甚至 GitHub issue 都无法使用。但是你不能剥夺他们参与开源项目的权利，而 mailing list 是一种很好的交流方式。&lt;/li&gt;
&lt;li&gt;通过 mailing list 可以很好掌握社区动态，效果明显好于 GitHub watch ，因为并不是项目的所有 commit 都是你关心的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;如果你有志于参与到开源运动，在享受开源软件带来便利的同事，还想为开源软件做出自己的贡献，那么 mailing list 是你进入社区最好的选择。在 mailing list 中和来自世界各地志同道合的开发者交流中提升自己的能力，创造更大的价值，迈出你参与开源运动的第一步。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（五）：配合 kubedog 完善 CI/CD 的最后一步</title>
      <link>https://guoxudong.io/en/post/kustomize-5/</link>
      <pubDate>Wed, 03 Jul 2019 15:20:31 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-5/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;在以往的 pipeline 中，使用 kubectl 进行部署 Deployment 后无法检查 Deployment 是否部署成功，只能通过使用命令/脚本来手动检查 Deployment 状态，而 kubedog 这个小工具完美解决了这个问题，完善了 CI/CD 流水线的最后一步。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;kubedog&#34;&gt;KubeDog&lt;/h2&gt;

&lt;p&gt;kubedog 是一个 lib 库和 CLI 小工具，允许在 CI/CD 部署 pipeline 中观察和跟踪 Kubernetes 资源。与 kustomize 配合，集成到 pipeline 之后，完美的解决了 CI/CD 的最后一步，完美的替代了之前不够灵活的脚本（好吧，其实我也开发了类似的小工具，但是有这么好用的轮子，拿来直接用何乐而不为呢？）。&lt;/p&gt;

&lt;p&gt;kubedog 提供了 lib 库和 CLI 小工具，这里由于是介绍 CI/CD 中的实践，所以只介绍其中的 &lt;code&gt;rollout track&lt;/code&gt; 功能。 lib 库的使用和 CLI 的 &lt;code&gt;follow&lt;/code&gt; 功能这里就不做介绍了，有兴趣的同学可以去 &lt;a href=&#34;https://github.com/flant/kubedog&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; 上查看该项目的各种使用方式。&lt;/p&gt;

&lt;h3 id=&#34;集成-kubedog&#34;&gt;集成 KubeDog&lt;/h3&gt;

&lt;p&gt;由于我司目前使用的是 &lt;a href=&#34;https://drone.io/&#34; target=&#34;_blank&#34;&gt;drone&lt;/a&gt; 进行 CI ，每个 step 都是由一个 docker 制作的插件组成。我制作了一个包含 &lt;code&gt;kubectl&lt;/code&gt; 、 &lt;code&gt;kustomize&lt;/code&gt; 和 &lt;code&gt;kubedog&lt;/code&gt; 的镜像。该镜像已上传 dockerhub ，需要的可以自行拉取使用 &lt;code&gt;guoxudongdocker/kubectl&lt;/code&gt; ,而该插件的使用也在 &lt;a href=&#34;https://github.com/sunny0826/kubectl-kustomize&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; 和 &lt;a href=&#34;https://cloud.docker.com/u/guoxudongdocker/repository/docker/guoxudongdocker/kubectl&#34; target=&#34;_blank&#34;&gt;DockerHub&lt;/a&gt; 上查看。&lt;/p&gt;

&lt;p&gt;而集成方式也比较简单，直接将 &lt;code&gt;kubectl&lt;/code&gt; 、 &lt;code&gt;kustomize&lt;/code&gt; 和 &lt;code&gt;kubedog&lt;/code&gt; 的可执行包下载到 &lt;code&gt;/usr/local/bin&lt;/code&gt; 并赋予执行权限即可，下面就是 &lt;code&gt;Dockerfile&lt;/code&gt; 文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;FROM alpine

LABEL maintainer=&amp;quot;sunnydog0826@gmail.com&amp;quot;

ENV KUBE_LATEST_VERSION=&amp;quot;v1.14.1&amp;quot;

RUN apk add --update ca-certificates \
 &amp;amp;&amp;amp; apk add --update -t deps curl \
 &amp;amp;&amp;amp; curl -L https://storage.googleapis.com/kubernetes-release/release/${KUBE_LATEST_VERSION}/bin/linux/amd64/kubectl -o /usr/local/bin/kubectl \
 &amp;amp;&amp;amp; chmod +x /usr/local/bin/kubectl \
 &amp;amp;&amp;amp; curl -L https://github.com/kubernetes-sigs/kustomize/releases/download/v2.0.3/kustomize_2.0.3_linux_amd64 -o /usr/local/bin/kustomize \
 &amp;amp;&amp;amp; chmod +x /usr/local/bin/kustomize \
 &amp;amp;&amp;amp; curl -L https://dl.bintray.com/flant/kubedog/v0.2.0/kubedog-linux-amd64-v0.2.0 -o /usr/local/bin/kubedog \
 &amp;amp;&amp;amp; chmod +x /usr/local/bin/kubedog \
 &amp;amp;&amp;amp; apk del --purge deps \
 &amp;amp;&amp;amp; rm /var/cache/apk/*


WORKDIR /root
ENTRYPOINT [&amp;quot;kubectl&amp;quot;]
CMD [&amp;quot;help&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kustomize-配合-kubedog-使用&#34;&gt;Kustomize 配合 KubeDog 使用&lt;/h2&gt;

&lt;p&gt;在镜像构建好之后就可以直接使用了，这里使用的是 DockerHub 的镜像仓库，这里建议将镜像同步到私有仓库，比如阿里云的容器镜像服务或者 Habor ，因为国内拉取 DockerHub 的镜像不太稳定，经常会拉取镜像失败或者访问超时，在 CI/CD 流水线中推荐使用更稳定镜像。&lt;/p&gt;

&lt;p&gt;以下是 &lt;code&gt;.drone.yml&lt;/code&gt; 示例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kind: pipeline
name: {your-pipeline-name}

steps:
- name: Kubernetes 部署
  image: guoxudongdocker/kubectl
  volumes:
  - name: kube
    path: /root/.kube
  commands:
    - cd deploy/overlays/dev    # 这里使用 kustomize ,详细使用方法请见 https://github.com/kubernetes-sigs/kustomize
    - kustomize edit set image {your-docker-registry}:${DRONE_BUILD_NUMBER}
    - kubectl apply -k . &amp;amp;&amp;amp; kubedog rollout track deployment {your-deployment-name} -n {your-namespace} -t {your-tomeout}

...

volumes:
- name: kube
  host:
    path: /tmp/cache/.kube  # kubeconfig 挂载位置

trigger:
  branch:
  - master  # 触发 CI 的分支
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的配置可见，在该 step 中执行了如下几步：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;进入 patch 所在路径&lt;/li&gt;
&lt;li&gt;使用了 Kustomize 命令 &lt;code&gt;kustomize edit set image {your-docker-registry}:${DRONE_BUILD_NUMBER}&lt;/code&gt; 方式将前面 step 中构建好的镜像的 tag 插入到 patch 中&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;kubectl apply -k .&lt;/code&gt; 进行 k8s 部署，要注意最后的那个 &lt;code&gt;.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;使用 kubedog 跟踪 Deployment 部署状态&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;命令解析：&lt;code&gt;kubedog rollout track deployment {your-deployment-name} -n {your-namespace} -t {your-tomeout}&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;deployment {your-deployment-name} : Deployment 的名称&lt;/li&gt;
&lt;li&gt;-n {your-namespace} : Deployment 所在的 namespace&lt;/li&gt;
&lt;li&gt;-t {your-tomeout} : 超时时间，单位为秒，超时后会报错，这里请根据实际部署情况进行设置&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;从 Kubernetes release v1.14 版本开始，&lt;code&gt;kustomize&lt;/code&gt; 集成到 &lt;code&gt;kubectl&lt;/code&gt; 中，越来越多 k8S 周边的小工具出现。这些小工具的出现帮助了 Kubernetes 的使用者来拉平 Kubernetes 的使用曲线，同时也标志着 K8S 的成熟，越来越多的开发人员基于使用 K8S 的痛点开发相关工具。套用一句今年 KubeCon 的 Keynote 演讲上，阿里云智能容器平台负责人丁宇的话： &lt;strong&gt;Kubernetes 正当时，云原生未来可期&lt;/strong&gt; 。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>记一次使用 Kustomize 时遇到的愚蠢问题</title>
      <link>https://guoxudong.io/en/post/kustomize-err-1/</link>
      <pubDate>Wed, 03 Jul 2019 13:44:50 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-err-1/</guid>
      <description>

&lt;h2 id=&#34;现象&#34;&gt;现象&lt;/h2&gt;

&lt;p&gt;在日常 CI/CD 流程中，已经将 Kustomize 集成到 pipeline 中使用，但是在对一个项目进行 Kustomize 改造时，将单个 &lt;code&gt;deploy.yaml&lt;/code&gt; 拆分为了若干个 patch 以达到灵活 Kubernetes 部署的目的。但是在使用 &lt;code&gt;kubectl apply -k .&lt;/code&gt; 命令进行部署的时候遇到了 &lt;code&gt;error: failed to find an object with apps_v1_Deployment|myapp to apply the patch&lt;/code&gt; 的报错。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://wx3.sinaimg.cn/large/ad5fbf65gy1g4mm1m3vx9j21oe10y102.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;解决之路&#34;&gt;解决之路&lt;/h2&gt;

&lt;p&gt;由于之前的使用中没有遇到此类报错，看报错信息像是 &lt;code&gt;apiVersion&lt;/code&gt; 的问题，所以先检查了所有 patch 的 &lt;code&gt;apiVersion&lt;/code&gt; ，但是并没有找到有什么问题。&lt;/p&gt;

&lt;h3 id=&#34;google-搜索&#34;&gt;Google 搜索&lt;/h3&gt;

&lt;p&gt;对该报错进行了搜索，搜索到如下结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ws4.sinaimg.cn/large/ad5fbf65gy1g4mmee8ctxj21900ns44c.jpg&#34; alt=&#34;image&#34; /&gt;
&lt;img src=&#34;https://wx4.sinaimg.cn/large/ad5fbf65gy1g4mmgrdz0fj21ou1b6wro.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;？？？ 为何这个 issue 没有解决就被提出者关闭了？&lt;/p&gt;

&lt;h3 id=&#34;问题解决&#34;&gt;问题解决&lt;/h3&gt;

&lt;p&gt;在 Google 了一圈之后还是没有找到什么有营养的回答，问题又回到了原点&amp;hellip;只能对所有的 patch 的每个字符和每个配置逐一进行了检查。结果发现是 &lt;code&gt;name&lt;/code&gt; 的内容 base 与 overlays 不同&amp;hellip; base 中是 &lt;code&gt;name:myapp&lt;/code&gt; ，而 overlays 中是 &lt;code&gt;name:my-app&lt;/code&gt; &amp;hellip;&lt;/p&gt;

&lt;p&gt;好吧，issue 关的是有道理的&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wx1.sinaimg.cn/large/ad5fbf65gy1g4mmuqm6n2j2098048a9z.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（四）：简述核心配置 kustomization.yaml</title>
      <link>https://guoxudong.io/en/post/kustomize-4/</link>
      <pubDate>Thu, 23 May 2019 12:50:12 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-4/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;在前面的文章中已经介绍了 kustomize 是什么，以及如何开始使用和如何简单的在 CI/CD 中使用，本篇文章将会介绍 kustomize 的核心文件 &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/zh/kustomization.yaml&#34; target=&#34;_blank&#34;&gt;kustomization.yaml&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;另外，博主已经向 kustomize 贡献了中文文档，已被官方采纳，现在在 kustomize 中的 &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/tree/master/docs/zh&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docs/zh&lt;/code&gt;&lt;/a&gt; 目录中就可看到，翻译的不好的地方欢迎指正。同时也在 GitHub 上新建了一个 名为 &lt;a href=&#34;https://github.com/sunny0826/kustomize-lab&#34; target=&#34;_blank&#34;&gt;kustomize-lab&lt;/a&gt; 的 repo 用于演示 kustomize 的各种用法及技巧，本文中介绍的内容也会同步更新到该 repo 中，欢迎 fork、star、PR。&lt;/p&gt;

&lt;h2 id=&#34;kustomization-yaml-的作用&#34;&gt;&lt;code&gt;kustomization.yaml&lt;/code&gt; 的作用&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Kustomize 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;有前面的文章&lt;a href=&#34;../kustomize-2&#34;&gt;《使用 Kustomize 帮你管理 kubernetes 应用（二）： Kustomize 的使用方法》&lt;/a&gt;中已经介绍了，每个 &lt;code&gt;base&lt;/code&gt; 或 &lt;code&gt;overlays&lt;/code&gt; 中都必须要有一个 &lt;code&gt;kustomization.yaml&lt;/code&gt;，这里我们看一下官方示例 &lt;code&gt;helloWorld&lt;/code&gt; 中的 &lt;code&gt;kustomization.yaml&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;commonLabels:
  app: hello

resources:
- deployment.yaml
- service.yaml
- configMap.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到该项目中包含3个 resources ， &lt;code&gt;deployment.yaml&lt;/code&gt;、&lt;code&gt;service.yaml&lt;/code&gt; 、 &lt;code&gt;configMap.yaml&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.
└── helloWorld
    ├── configMap.yaml
    ├── deployment.yaml
    ├── kustomization.yaml
    └── service.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;直接执行命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build helloWorld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以看到结果了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;apiVersion: v1
data:
  altGreeting: Good Morning!
  enableRisky: &amp;quot;false&amp;quot;
kind: ConfigMap
metadata:
  labels:
    app: hello
  name: the-map
image:
  caption: &amp;quot;Image from: [**Pexels**](https://www.pexels.com)&amp;quot;
  focal_point: &amp;quot;&amp;quot;
  preview_only: false
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hello
  name: the-service
spec:
  ports:
  - port: 8666
    protocol: TCP
    targetPort: 8080
  selector:
    app: hello
    deployment: hello
  type: LoadBalancer
image:
  caption: &amp;quot;Image from: [**Pexels**](https://www.pexels.com)&amp;quot;
  focal_point: &amp;quot;&amp;quot;
  preview_only: false
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: hello
  name: the-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hello
  template:
    metadata:
      labels:
        app: hello
        deployment: hello
    spec:
      containers:
      - command:
        - /hello
        - --port=8080
        - --enableRiskyFeature=$(ENABLE_RISKY)
        env:
        - name: ALT_GREETING
          valueFrom:
            configMapKeyRef:
              key: altGreeting
              name: the-map
        - name: ENABLE_RISKY
          valueFrom:
            configMapKeyRef:
              key: enableRisky
              name: the-map
        image: monopole/hello:1
        name: the-container
        ports:
        - containerPort: 8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的结果可以看大 kustomize 通过 &lt;code&gt;kustomization.yaml&lt;/code&gt; 将3个 resources 进行了处理，给三个 resources 添加了共同的 labels &lt;code&gt;app: hello&lt;/code&gt; 。这个示例展示了 &lt;code&gt;kustomization.yaml&lt;/code&gt; 的作用：&lt;strong&gt;将不同的 resources 进行整合，同时为他们加上相同的配置&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&#34;进阶使用&#34;&gt;进阶使用&lt;/h2&gt;

&lt;p&gt;上面只不过是一个简单的示例，下面将结合实际情况分享一些比较实用的用法&lt;/p&gt;

&lt;h3 id=&#34;根据环境生成不同配置&#34;&gt;根据环境生成不同配置&lt;/h3&gt;

&lt;p&gt;在实际的使用中，使用最多的就是为不同的环境配置不同的 &lt;code&gt;deploy.yaml&lt;/code&gt;，而使用 kustomize 可以把配置拆分为多个小的 patch ，然后通过 kustomize 来进行组合。而根据环境的不同，每个 patch 都可能不同，包括分配的资源、访问的方式、部署的节点都可以自由的定制。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.
├── flask-env
│   ├── README.md
│   ├── base
│   │   ├── deployment.yaml
│   │   ├── kustomization.yaml
│   │   └── service.yaml
│   └── overlays
│       ├── dev
│       │   ├── healthcheck_patch.yaml
│       │   ├── kustomization.yaml
│       │   └── memorylimit_patch.yaml
│       └── prod
│           ├── healthcheck_patch.yaml
│           ├── kustomization.yaml
│           └── memorylimit_patch.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里可以看到配置分为了 &lt;code&gt;base&lt;/code&gt; 和 &lt;code&gt;overlays&lt;/code&gt;， &lt;code&gt;overlays&lt;/code&gt; 则是继承了 &lt;code&gt;base&lt;/code&gt; 的配置，同时添加了诸如 healthcheck 和 memorylimit 等不同的配置，那么我们分别看一下 &lt;code&gt;base&lt;/code&gt; 和 &lt;code&gt;overlays&lt;/code&gt; 中 &lt;code&gt;kustomization.yaml&lt;/code&gt; 的内容&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;base&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;commonLabels:
app: test-cicd

resources:
- service.yaml
- deployment.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;base&lt;/code&gt; 中的 &lt;code&gt;kustomization.yaml&lt;/code&gt; 中定义了一些基础配置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;overlays&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;bases:
- ../../base
patchesStrategicMerge:
- healthcheck_patch.yaml
- memorylimit_patch.yaml
namespace: devops-dev
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;overlays&lt;/code&gt; 中的 &lt;code&gt;kustomization.yaml&lt;/code&gt; 则是基于 &lt;code&gt;base&lt;/code&gt; 新增了一些个性化的配置，来达到生成不同环境的目的。&lt;/p&gt;

&lt;p&gt;执行命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build flask-env/overlays/dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;apiVersion: v1
kind: Service
metadata:
  labels:
    app: test-cicd
  name: test-cicd
  namespace: devops-dev
spec:
  ports:
  - name: http
    port: 80
    targetPort: 80
  selector:
    app: test-cicd
  type: ClusterIP
image:
  caption: &amp;quot;Image from: [**Pexels**](https://www.pexels.com)&amp;quot;
  focal_point: &amp;quot;&amp;quot;
  preview_only: false
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: test-cicd
  name: test-cicd
  namespace: devops-dev
spec:
  replicas: 1
  selector:
    matchLabels:
      app: test-cicd
  template:
    metadata:
      labels:
        app: test-cicd
        version: 0.0.3
    spec:
      containers:
      - env:
        - name: ENV
          value: dev
        image: guoxudongdocker/flask-python:latest
        imagePullPolicy: Always
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 20
        name: test-cicd
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 20
        resources:
          limits:
            cpu: 300m
            memory: 500Mi
          requests:
            cpu: 300m
            memory: 500Mi
        volumeMounts:
        - mountPath: /etc/localtime
          name: host-time
      imagePullSecrets:
      - name: registry-pull-secret
      volumes:
      - hostPath:
          path: /etc/localtime
        name: host-time
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到包括 &lt;code&gt;replicas&lt;/code&gt;、&lt;code&gt;limits&lt;/code&gt;、&lt;code&gt;requests&lt;/code&gt;、&lt;code&gt;env&lt;/code&gt; 等 dev 中个性的配置都已经出现在了生成的 yaml 中。由于篇幅有限，这里没有把所有的配置有罗列出来，需要的可以去 &lt;a href=&#34;https://github.com/sunny0826/kustomize-lab&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; 上自取。&lt;/p&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;上面所有的 &lt;code&gt;kustomize build dir/&lt;/code&gt; 都可以使用 &lt;code&gt;kubectl apply -k dir/&lt;/code&gt; 实现，但是需要 &lt;code&gt;v14.0&lt;/code&gt; 版以上的 &lt;code&gt;kubectl&lt;/code&gt;，也就是说，其实我们在集成到 CI/CD 中的时候，甚至都不需要用来 &lt;code&gt;kustomize&lt;/code&gt; 命令集，有 &lt;code&gt;kubectl&lt;/code&gt; 就够了。&lt;/p&gt;

&lt;p&gt;由于篇幅有限，这里没法吧所有 &lt;code&gt;kustomization.yaml&lt;/code&gt; 的用途都罗列出来，不过可以在官方文档中找到我提交的中文翻译版 &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/zh/kustomization.yaml&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;kustomization.yaml&lt;/code&gt;&lt;/a&gt;，可以直接去官方 GitHub 查看。同时 &lt;a href=&#34;https://github.com/sunny0826/kustomize-lab&#34; target=&#34;_blank&#34;&gt;kustomize-lab&lt;/a&gt; 会持续更行，敬请关注。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（三）：将 Kustomize 应用于 CI/CD</title>
      <link>https://guoxudong.io/en/post/kustomize-3/</link>
      <pubDate>Mon, 06 May 2019 16:46:28 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-3/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;首先明确软件版本，我这里使用的是 &lt;code&gt;Jenkins ver. 2.121.3&lt;/code&gt; ，这个版本比较老，其上安装 Kubernetes 插件所使用 &lt;code&gt;kubectl&lt;/code&gt; 版本也比较老，&lt;strong&gt;无法使用&lt;/strong&gt; Kustomize 的 yaml 文件需要的 &lt;code&gt;apiVersion: apps/v1&lt;/code&gt; ，直接使用生成 &lt;code&gt;deploy.yaml&lt;/code&gt; 文件会报错，所以这里选择了自己构建一个包含 &lt;code&gt;kubectl&lt;/code&gt; 和 &lt;code&gt;kustomize&lt;/code&gt; 的镜像，在镜像中使用 Kustomize 生成所需 yaml 文件并在 Kubernetes 上部署。&lt;/p&gt;

&lt;h2 id=&#34;软件版本&#34;&gt;软件版本&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;软件&lt;/th&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Jenkins&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://jenkins.io/&#34; target=&#34;_blank&#34;&gt;2.121.3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;kubectl&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34; target=&#34;_blank&#34;&gt;v1.14.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;kustomize&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/releases&#34; target=&#34;_blank&#34;&gt;v2.0.3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;前期准备&#34;&gt;前期准备&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Jenkins ：本篇使用 Jenkins 演示 CI/CD ，安装 Jenkins 就不在赘述，可以使用多种方法安装 Jenkins ，详细方法见&lt;a href=&#34;https://jenkins.io&#34; target=&#34;_blank&#34;&gt;官网&lt;/a&gt;。同时。 CI/CD 的工具有很多，这里为了省事使用笔者现有的 Jenkins 进行演示，&lt;strong&gt;不推荐&lt;/strong&gt;使用同笔者一样的版本，请使用较新的版本；同时也可以使用其他 CI/CD 工具，这里推荐使用 &lt;a href=&#34;https://drone.io/&#34; target=&#34;_blank&#34;&gt;drone&lt;/a&gt;。如果有更好的方案，欢迎交流，可以在&lt;a href=&#34;https://blog.maoxianplay.com/contact/&#34; target=&#34;_blank&#34;&gt;关于&lt;/a&gt;中找到我的联系方式。&lt;/li&gt;

&lt;li&gt;&lt;pre&gt;&lt;code class=&#34;language-kubectl```&#34;&gt;- Web 应用：这里使用 flask 写了一个简单的 web 应用，用于演示，同样以上传 dockerhub [```guoxudongdocker/flask-python```](https://hub.docker.com/r/guoxudongdocker/flask-python)

## 目录结构

首先看一下目录结构，目录中包括 ```Dockerfile``` 、 ```Jenkinsfile``` 、 Kustomize 要使用的 ```deploy``` 目录以及 web 应用目录。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bush&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;.
├── Dockerfile
├── Jenkinsfile
├── app
│   ├── main.py
│   └── uwsgi.ini
└── deploy
    ├── base
    │   ├── deployment.yaml
    │   ├── kustomization.yaml
    │   └── service.yaml
    └── overlays
        ├── dev
        │   ├── healthcheck_patch.yaml
        │   ├── kustomization.yaml
        │   └── memorylimit_patch.yaml
        └── prod
            ├── healthcheck_patch.yaml
            ├── kustomization.yaml
            └── memorylimit_patch.yaml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
这里可以看到 overlays 总共有两个子目录 `dev` 和 `prod` ，分别代表不同环境，在不同的环境中，应用不同的配置。

## Jenkins 配置

Jenkins 的配置相对简单，只需要新建一个 pipeline 类型的 job

![WX20190506-180159](https://wx4.sinaimg.cn/large/ad5fbf65gy1g2rr57oixbj20tn0ogq6v.jpg)

增加参数化构建，**注**：参数化构建需要安装 Jenkins 插件

![WX20190506-180918](https://ws4.sinaimg.cn/large/ad5fbf65gy1g2rrcb5ic9j21470q7mz8.jpg)

然后配置代码仓库即可

![WX20190507-094958](https://ws3.sinaimg.cn/large/ad5fbf65gy1g2sij1xlb2j214w0nw0uw.jpg)

## Pipeline 

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;groovy
podTemplate(label: &amp;lsquo;jnlp-slave&amp;rsquo;, cloud: &amp;lsquo;kubernetes&amp;rsquo;,
  containers: [
    containerTemplate(
        name: &amp;lsquo;jnlp&amp;rsquo;,
        image: &amp;lsquo;guoxudongdocker/jenkins-slave&amp;rsquo;,
        alwaysPullImage: true
    ),
    containerTemplate(name: &amp;lsquo;kubectl&amp;rsquo;, image: &amp;lsquo;guoxudongdocker/kubectl:v1.14.1&amp;rsquo;, command: &amp;lsquo;cat&amp;rsquo;, ttyEnabled: true),
  ],
  nodeSelector:&amp;lsquo;ci=jenkins&amp;rsquo;,
  volumes: [
    hostPathVolume(mountPath: &amp;lsquo;/var/run/docker.sock&amp;rsquo;, hostPath: &amp;lsquo;/var/run/docker.sock&amp;rsquo;),
    hostPathVolume(mountPath: &amp;lsquo;/usr/bin/docker&amp;rsquo;, hostPath: &amp;lsquo;/usr/bin/docker&amp;rsquo;),
    hostPathVolume(mountPath: &amp;lsquo;/usr/local/jdk&amp;rsquo;, hostPath: &amp;lsquo;/usr/local/jdk&amp;rsquo;),
    hostPathVolume(mountPath: &amp;lsquo;/usr/local/maven&amp;rsquo;, hostPath: &amp;lsquo;/usr/local/maven&amp;rsquo;),
    secretVolume(mountPath: &amp;lsquo;/home/jenkins/.kube&amp;rsquo;, secretName: &amp;lsquo;devops-ctl&amp;rsquo;),
  ],
)
{
    node(&amp;ldquo;jnlp-slave&amp;rdquo;){
        stage(&amp;lsquo;Git Checkout&amp;rsquo;){
            git branch: &amp;lsquo;${branch}&amp;rsquo;, url: &amp;lsquo;&lt;a href=&#34;https://github.com/sunny0826/flask-python.git&#39;&#34; target=&#34;_blank&#34;&gt;https://github.com/sunny0826/flask-python.git&#39;&lt;/a&gt;
        }
        stage(&amp;lsquo;Build and Push Image&amp;rsquo;){
            withCredentials([usernamePassword(credentialsId: &amp;lsquo;docker-register&amp;rsquo;, passwordVariable: &amp;lsquo;dockerPassword&amp;rsquo;, usernameVariable: &amp;lsquo;dockerUser&amp;rsquo;)]) {
                sh &amp;ldquo;&amp;rsquo;
                docker login -u ${dockerUser} -p ${dockerPassword}
                docker build -t guoxudongdocker/flask-python:${Tag} .
                docker push guoxudongdocker/flask-python:${Tag}
                &amp;ldquo;&amp;rsquo;
            }
        }
        stage(&amp;lsquo;Deploy to K8s&amp;rsquo;){
            if (&amp;lsquo;true&amp;rsquo; == &amp;ldquo;${deploy}&amp;rdquo;) {
                container(&amp;lsquo;kubectl&amp;rsquo;) {
                    sh &amp;ldquo;&amp;rsquo;
                    cd deploy/base
                    kustomize edit set image guoxudongdocker/flask-python:${Tag}
                    &amp;ldquo;&amp;rsquo;
                    echo &amp;ldquo;部署到 Kubernetes&amp;rdquo;
                    if (&amp;lsquo;prod&amp;rsquo; == &amp;ldquo;${ENV}&amp;rdquo;) {
                        sh &amp;ldquo;&amp;rsquo;
                        # kustomize build deploy/overlays/prod | kubectl apply -f -
                        kubectl applt -k deploy/overlays/prod
                        &amp;ldquo;&amp;rsquo;
                    }else {
                        sh &amp;ldquo;&amp;rsquo;
                        # kustomize build deploy/overlays/dev | kubectl apply -f -
                        kubectl applt -k deploy/overlays/dev
                        &amp;ldquo;&amp;rsquo;
                    }	
                }
            }else{
                echo &amp;ldquo;跳过Deploy to K8s&amp;rdquo;
            }&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
这里要注意几点：

- 拉取 git 中的代码需要在 jenkins 中配置凭据。
- 笔者的 jenkins 部署在 Kubernetes 上，要操作集群的话，需要将 kubeconfig 以 Secret 的形式挂载到 jenkins 所在 namespace。
- `jenkins-slave` 需要 Java 环境运行，所以要将宿主机的 `jdk` 挂载到 `jenkins-slave` 中。
- 同样的，宿主机中需要事先安装 `docker`。
- `docker-register` 为 dockerhub 的登录凭证，需要在 jenkins 中添加相应的凭证。

## 演示

image:
  caption: &amp;quot;Image from: [**Pexels**](https://www.pexels.com)&amp;quot;
  focal_point: &amp;quot;&amp;quot;
  preview_only: false
---

### 开始构建

这里选择环境、分支，填入版本即可开始构建，**注意：**这里的版本将已 tag 的形式标记 docker 镜像。

![WX20190507-095142](https://ws2.sinaimg.cn/large/ad5fbf65gy1g2sikst7tuj20ob0evabw.jpg)

这里就可以看到构建成功了

![WX20190507-103721](https://ws2.sinaimg.cn/large/ad5fbf65ly1g2sjw9w22ej20v80km0w3.jpg)

### 查看结果

这里为了方便（其实就是懒），我就不给这个服务添加 ingress 来从外部访问了，这里使用 [KT](https://yq.aliyun.com/articles/690519) 打通本地和 k8s 集群网络来进行调试。

&amp;gt;为了简化在Kubernetes下进行联调测试的复杂度，云效在SSH隧道网络的基础上并结合Kubernetes特性构建了一款面向开发者的辅助工具kt

这里看到这个服务正常启动了

![WX20190507-104154](https://ws2.sinaimg.cn/large/ad5fbf65ly1g2sk11dnzxj20av027jrn.jpg)

### 发布新版本

更新 web 服务并提交

![WX20190507-104936](https://ws4.sinaimg.cn/large/ad5fbf65gy1g2sk94v1c5j209702vwej.jpg)


按照上面步骤在 jenkins 中重新构建，当然也可以配置钩子，每次代码提交后自动构建

### 查看查看新版本

同上面一样，在构建成功后查看服务是否更新

![WX20190507-105539](https://wx4.sinaimg.cn/large/ad5fbf65gy1g2skfczaz4j20by01smx7.jpg)

可以看到，版本已经更新了

### 发布生产环境

这里模拟一下发布生产环境，假设生产环境是在 `devops-prod` 的 namespace 中，这里只做演示之用，真正的生产环境中，可能存在不止一个 k8s 集群，这时需要修改 Jenkinsfile 中的 `secretVolume` 来挂载不同 k8s 的 kubeconfig 来达到发布到不同集群的目的。当然，一般发布生产环境只需选择测试通过的镜像来发布即可，不需要在进行构建打包。

![WX20190507-110730](https://ws3.sinaimg.cn/large/ad5fbf65gy1g2skrnbjyuj20fc0bjmxp.jpg)

### 查看生产版本

![WX20190507-110850](https://ws1.sinaimg.cn/large/ad5fbf65ly1g2skt3rp4yj20aq010glj.jpg)

### 总结

上面的这些步骤简单的演示了使用 jenkins 进行 CI/CD 的流程，流程十分简单，这里仅供参考

## Kustomize 的作用

那么， Kustomize 在整个流程中又扮演了一个什么角色呢？

### 更新镜像

在 `jenkinsfile` 中可以看到， kustomize 更新了基础配置的镜像版本，这里我们之前一直是使用 `sed -i &amp;quot;s/#Tag/${Tag}/g&amp;quot; deploy.yaml` 来进行替换了，但是不同环境存在比较多的差异，需要替换的越来越多，导致 Jekninsfile 也越来越臃肿和难以维护。 kustomize 解决了这个问题。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bash
kustomize edit set image guoxudongdocker/flask-python:${Tag}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
### 环境区分

上面也提到了，不同的环境我们存在这许多差异，虽然看上去大致类似，但是很多细节都需要修改。这时 kustomize 就起到了很大的作用，不同环境相同的配置都放在 `base` 中，而差异就可以在 `overlays` 中实现。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bash
.
├── base
│   ├── deployment.yaml
│   ├── kustomization.yaml
│   └── service.yaml
└── overlays
    ├── dev
    │   ├── healthcheck_patch.yaml
    │   ├── kustomization.yaml
    │   └── memorylimit_patch.yaml
    └── prod
        ├── healthcheck_patch.yaml
        ├── kustomization.yaml
        └── memorylimit_patch.yaml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;可以看到， `base` 中维护了项目共同的基础配置，如果有镜像版本等基础配置需要修改，可以使用 `kustomize edit set image ...` 来直接修改基础配置，而真正不同环境，或者不同使用情况的配置则在 `overlays` 中 以 patch 的形式添加配置。这里我的配置是 prod 环境部署的副本为2，同时给到的资源也更多，详情可以在 [Github](https://github.com/sunny0826/flask-python) 上查看。

### 与 kubectl 的集成

在 jenkinsfile 中可以看到

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bash&lt;/p&gt;

&lt;h1 id=&#34;kustomize-build-deploy-overlays-dev-kubectl-apply-f&#34;&gt;kustomize build deploy/overlays/dev | kubectl apply -f -&lt;/h1&gt;

&lt;p&gt;kubectl apply -k deploy/overlays/dev
```&lt;/p&gt;

&lt;p&gt;这两条命令的执行效果是一样的，在 &lt;code&gt;kubectl v1.14.0&lt;/code&gt; 以上的版本中，已经集成了 kustomize ，可以直接使用 &lt;code&gt;kubectl&lt;/code&gt; 进行部署。&lt;/p&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;这里只是对 kustomize 在 CI/CD 中简单应用的展示，只是一种比较简单和基础的使用，真正的 CI 流程要比这个复杂的多，这里只是为了演示 kustomize 的使用而临时搭建的。而 kustomize 还有很多黑科技的用法，将会在后续的文章中介绍。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（二）： Kustomize 的使用方法</title>
      <link>https://guoxudong.io/en/post/kustomize-2/</link>
      <pubDate>Fri, 19 Apr 2019 16:05:02 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-2/</guid>
      <description>

&lt;p&gt;本文介绍使用和维护 Kustomize 的方法及步骤。&lt;/p&gt;

&lt;h2 id=&#34;定制配置&#34;&gt;定制配置&lt;/h2&gt;

&lt;p&gt;在这个工作流方式中，所有的配置文件（ YAML 资源）都为用户所有，存在于私有 repo 中。其他人是无法使用的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://wx4.sinaimg.cn/large/ad5fbf65gy1g2813d1ia7j20qo0f0dgk.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;创建一个目录用于版本控制&lt;/p&gt;

&lt;p&gt;我们希望将一个名为 &lt;strong&gt;&lt;em&gt;ldap&lt;/em&gt;&lt;/strong&gt; 的 Kubernetes 集群应用的配置保存在自己的 repo 中。
这里使用 &lt;code&gt;git&lt;/code&gt; 进行版本控制。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git init ~/ldap
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;创建一个 &lt;code&gt;base&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/ldap/base
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在这个目录中创建并提交 &lt;code&gt;kustomization.yaml&lt;/code&gt; 文件和一组资源，例如 &lt;code&gt;deployment.yaml&lt;/code&gt; &lt;code&gt;service.yaml&lt;/code&gt; 等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;创建 &lt;code&gt;overlays&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/ldap/overlays/staging
mkdir -p ~/ldap/overlays/production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每个目录都需要一个 &lt;code&gt;kustomization.yaml&lt;/code&gt; 文件以及一个或多个 &lt;code&gt;patch&lt;/code&gt; ，例如 &lt;code&gt;healthcheck_patch.yaml&lt;/code&gt; &lt;code&gt;memorylimit_patch.yaml&lt;/code&gt; 等。。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-staging```&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;production&lt;code&gt;目录则可能会在&lt;/code&gt;deployment``` 中增加在副本数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;生成 &lt;code&gt;variants&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;运行 &lt;code&gt;kustomize&lt;/code&gt; ，将生成的配置用于 kubernetes 应用部署&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build ~/ldap/overlays/staging | kubectl apply -f -
kustomize build ~/ldap/overlays/production | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 kubernetes 1.14 版本， &lt;code&gt;kustomize&lt;/code&gt; 已经集成到 &lt;code&gt;kubectl&lt;/code&gt; 命令中，成为了其一个子命令，可使用 &lt;code&gt;kubectl&lt;/code&gt; 来进行部署&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl apply -k ~/ldap/overlays/staging
kubectl apply -k ~/ldap/overlays/production
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;使用现成的配置&#34;&gt;使用现成的配置&lt;/h2&gt;

&lt;p&gt;在这个工作流方式中，可从别人的 repo 中 fork kustomize 配置，并根据自己的需求来配置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://wx4.sinaimg.cn/large/ad5fbf65gy1g281xyfebej20qo0f0dgr.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过 fork/modify/rebase 等方式获得配置&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;将其克隆为你自己的 &lt;code&gt;base&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在这个 &lt;code&gt;bash&lt;/code&gt; 目录维护在一个 repo 中，在这个例子使用 &lt;code&gt;ladp&lt;/code&gt; 的 repo&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir ~/ldap
git clone https://github.com/$USER/ldap ~/ldap/base
cd ~/ldap/base
git remote add upstream git@github.com:$USER/ldap
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;创建 &lt;code&gt;overlays&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如上面的案例一样，创建并完善 &lt;code&gt;overlays&lt;/code&gt; 目录中的内容&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/ldap/overlays/staging
mkdir -p ~/ldap/overlays/production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用户可以将 &lt;code&gt;overlays&lt;/code&gt; 维护在不同的 repo 中&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;生成 &lt;code&gt;variants&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build ~/ldap/overlays/staging | kubectl apply -f -
kustomize build ~/ldap/overlays/production | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 kubernetes 1.14 版本， &lt;code&gt;kustomize&lt;/code&gt; 已经集成到 &lt;code&gt;kubectl&lt;/code&gt; 命令中，成为了其一个子命令，可使用 &lt;code&gt;kubectl&lt;/code&gt; 来进行部署&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl apply -k ~/ldap/overlays/staging
kubectl apply -k ~/ldap/overlays/production
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;（可选）更新 &lt;code&gt;base&lt;/code&gt;
用户可以定期从上游 repo 中 &lt;code&gt;rebase&lt;/code&gt; 他们的 &lt;code&gt;base&lt;/code&gt; 以保证及时更新&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/ldap/base
git fetch upstream
git rebase upstream/master
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/workflows.md&#34; target=&#34;_blank&#34;&gt;kustomize workflows - github.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（一）：什么是 Kustomize ？</title>
      <link>https://guoxudong.io/en/post/kustomize-1/</link>
      <pubDate>Mon, 15 Apr 2019 13:32:59 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-1/</guid>
      <description>

&lt;h2 id=&#34;初识-kustomize&#34;&gt;初识 Kustomize&lt;/h2&gt;

&lt;p&gt;第一次听说 Kustomize 其实是在 kubernetes 1.14 发布时候，它被集成到 &lt;code&gt;kubectl&lt;/code&gt; 中，成为了一个子命令，但也只是扫了一眼，并没有深究。真正让我注意到它，并主动开始了解其功能和使用方法的，是张磊大神在云栖社区发表的一篇文章&lt;a href=&#34;https://yq.aliyun.com/articles/697883&#34; target=&#34;_blank&#34;&gt;《从Kubernetes 1.14 发布，看技术社区演进方向》&lt;/a&gt;，他在文中是这么说的：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Kustomize 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件，而不是像 Helm 那样只提供应用描述文件模板，然后通过字符替换（Templating）的方式来进行定制化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这不正我在苦苦寻找的东西嘛！自从公司确定了应用容器化的方案，至今已有半年多了，这期间我们的服务一个接一个的实现了容器化，部署到了 kubernetes 集群中。kubernetes 集群也有原先了1个测试集群，几个节点，发展到了如今的多个集群，几十个节点。而在推进容器化的过程中，每个服务都对对应多个应用描述文件（ YAML 文件），而根据环境的不同，又配置了多套的应用描述文件。随着服务越部越多，应用描述文件更是呈爆炸式的增长。&lt;/p&gt;

&lt;p&gt;感谢 devops 文化，它是我不需要为每个应用去写 YAML 文件，各个应用的开发组承担了这一工作，我只需要为他们提供基础模板即可。但应用上线后出现的 OOM 、服务无法拉起等 YAML 文件配置有误导致的问题接踵而至，使得我必须要深入各个服务，为他们配置符合他们配置。虽然也使用了 &lt;code&gt;helm&lt;/code&gt; ，但是其只提供应用描述文件模板，在不同环境拉起一整套服务会节省很多时间，而像我们这种在指定环境快速迭代的服务，并不会减少很多时间。针对这种情况，我已经计划要自己开发一套更符合我们工作这种场景的应用管理服务，集成在我们自己的 devops 平台中。&lt;/p&gt;

&lt;p&gt;这时 Kustomize 出现了，我明锐的感觉到 Kustomize 可能就是解决我现阶段问题的一剂良药。&lt;/p&gt;

&lt;h2 id=&#34;什么是-kustomize&#34;&gt;什么是 Kustomize ？&lt;/h2&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;kubernetes-native-configuration-management&#34;&gt;Kubernetes native configuration management&lt;/h4&gt;

&lt;p&gt;Kustomize introduces a template-free way to customize application configuration that simplifies the use of off-the-shelf applications. Now, built into &lt;code&gt;kubectl&lt;/code&gt; as &lt;code&gt;apply -k&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kustomize&lt;/code&gt;  允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。而其他用户可以完全不受影响的使用任何一个 Base YAML 或者任何一层生成出来的 YAML 。这使得每一个用户都可以通过类似fork/modify/rebase 这样 Git 风格的流程来管理海量的应用描述文件。这种 PATCH 的思想跟 Docker 镜像是非常相似的，它可以规避“字符替换”对应用描述文件的入侵，也不需要用户学习额外的 DSL 语法（比如 Lua）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;而其成为 &lt;code&gt;kubectl&lt;/code&gt; 子命令则代表这 &lt;code&gt;kubectl&lt;/code&gt; 本身的插件机制的成熟，未来可能有更多的工具命令集成到 &lt;code&gt;kubectl&lt;/code&gt; 中。拿张磊大神的这张图不难看出，在 kubernetes 原生应用管理系统中，应用描述文件在整个应用管理体系中占据核心位置，通过应用描述文件可以组合和编排多种 kubernetes API 资源，kubernetes 通过控制器来保证集群中的资源与应用状态与描述文件完全一致。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://wx4.sinaimg.cn/large/ad5fbf65gy1g23cqlrodkj21bq0r8znk.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Kustomize 不像 Helm 那样需要一整套独立的体系来完成管理应用，而是完全采用 kubernetes 的设计理念来完成管理应用的目的。同时使用起来也更加的得心应手。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kustomize.io/&#34; target=&#34;_blank&#34;&gt;Kustomize - kustomize.io&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://yq.aliyun.com/articles/697883&#34; target=&#34;_blank&#34;&gt;从Kubernetes 1.14 发布，看技术社区演进方向 - yq.aliyun.com&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
