<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>工具 on GuoXD Blog</title>
    <link>https://guoxudong.io/en/tags/%E5%B7%A5%E5%85%B7/</link>
    <description>Recent content in 工具 on GuoXD Blog</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&lt;a rel=&#39;license&#39; href=&#39;http://creativecommons.org/licenses/by-nc/4.0/&#39; target=&#39;_blank&#39;&gt;知识共享署名-非商业性使用 4.0 国际许可协议&lt;/a&gt;</copyright>
    <lastBuildDate>Wed, 11 Sep 2019 13:53:09 +0800</lastBuildDate>
    
	    <atom:link href="https://guoxudong.io/en/tags/%E5%B7%A5%E5%85%B7/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>玩转 Drone CI</title>
      <link>https://guoxudong.io/en/post/drone-optimize/</link>
      <pubDate>Wed, 11 Sep 2019 13:53:09 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/drone-optimize/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;使用 drone CI 已有小半年，在将原有项目的 CI 系统从 jenkins 向 drone 迁移的时候，也陆陆续续遇到了一些问题。在这段时间，也完成了使用官方插件到插件定制的转变，使得 drone CI 流程更贴合我们 devops 开发流程。通过这篇文章总结一下目前我们对 drone 进行的一些定制化开发以及使用技巧，由于 drone 官方的文档不是很详细，所以也希望通过这种方法来和其他使用 drone 的用户分享和交流使用经验。&lt;/p&gt;

&lt;h2 id=&#34;并行构建&#34;&gt;并行构建&lt;/h2&gt;

&lt;p&gt;在默认情况下，drone 会按照步骤执行，但是有时会遇到前后端在同一个 repo 的情况，这时使用并行构建就可以省去很多的构建时间。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;构建流程：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在下面的示例里会展示一个如下流程：repo 中包含一个由 Java 写的服务以及一个 vue 前端项目，maven 构建和 npm 构建同时进行，maven 构建成功后会镜像 docker 镜像构建并上传镜像仓库，docker 构建成功后会镜像 k8s 部署，部署成功后会进行 vue 项目前端发布，在 k8s 部署成功并且前端发布成功后，进行钉钉构建成功同时，否则进行钉钉构建失败通知。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;前端构建 ————————————          前端发布
                    \      /        \
                     \    /       钉钉通知
                      \  /          /
后端构建 —— 镜像构建 —— k8s部署 ——————

&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;.drone.yml&lt;/code&gt; 配置&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kind: &amp;quot;pipeline&amp;quot;
name: &amp;quot;default&amp;quot;
steps:
  - name: &amp;quot;Maven编译&amp;quot;
    image: &amp;quot;guoxudongdocker/drone-maven&amp;quot;
    commands:
      - &amp;quot;mvn clean install&amp;quot;
    depends_on: [ &amp;quot;clone&amp;quot; ]
  - name: &amp;quot;构建镜像&amp;quot;
    image: &amp;quot;guoxudongdocker/drone-docker&amp;quot;
    settings:
      username:
        from_secret: &amp;quot;docker_user&amp;quot;
      password:
        from_secret: &amp;quot;docker_pass&amp;quot;
      dockerfile: &amp;quot;Dockerfile&amp;quot;
      repo: &amp;quot;registry-vpc.cn-shanghai.aliyuncs.com/guoxudong/test&amp;quot;
      registry: &amp;quot;registry-vpc.cn-shanghai.aliyuncs.com&amp;quot;
      tags: &amp;quot;${DRONE_BUILD_NUMBER}&amp;quot;
    depends_on: [ &amp;quot;Maven编译&amp;quot; ]
  - name: &amp;quot;Kubernetes 部署&amp;quot;
    image: &amp;quot;guoxudongdocker/kubectl&amp;quot;
    settings:
      config: &amp;quot;deploy/overlays/uat&amp;quot;
      timeout: 300
      check: false
    depends_on: [ &amp;quot;构建镜像&amp;quot; ]
  - name: &amp;quot;前端构建&amp;quot;
    image: &amp;quot;guoxudongdocker/node-drone&amp;quot;
    commands:
      - &amp;quot;npm install&amp;quot;
      - &amp;quot;npm run build&amp;quot;
    depends_on: [ &amp;quot;clone&amp;quot; ]
  - name: &amp;quot;前端上传&amp;quot;
    image: &amp;quot;guoxudongdocker/node-drone&amp;quot;
    commands:
      - &amp;quot;do something&amp;quot;
    depends_on: [ &amp;quot;前端构建&amp;quot;,&amp;quot;Kubernetes 部署&amp;quot; ]
  - name: &amp;quot;钉钉通知&amp;quot;
    image: &amp;quot;guoxudongdocker/drone-dingtalk&amp;quot;
    settings:
      token:
        from_secret: &amp;quot;dingding&amp;quot;
      type: &amp;quot;markdown&amp;quot;
      message_color: true
      message_pic: true
      sha_link: true
    depends_on: [ &amp;quot;前端上传&amp;quot;,&amp;quot;Kubernetes 部署&amp;quot; ]
    when:
      status:
        - &amp;quot;failure&amp;quot;
        - &amp;quot;success&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;多子项目构建&#34;&gt;多子项目构建&lt;/h2&gt;

&lt;p&gt;在使用 drone 中遇到的最大问题就是，我们有很多项目都是在一个 repo 中有很多子项目，而每个子项目都是 k8s 中的一个服务，这时一个 &lt;code&gt;.drone.yml&lt;/code&gt; 文件很难把所有的服务都囊括。而又不想每个子项目拉一个分支管理，当前的模式就很不合适。&lt;/p&gt;

&lt;h3 id=&#34;插件开发&#34;&gt;插件开发&lt;/h3&gt;

&lt;p&gt;针对这个问题，我们对 drone 进行了定制化开发，会在每次提交代码后，对新提交的代码和老代码进行比较，筛选出做了修改的子项目，然后对有修改的子项目尽心 CI ，其余的子项目则不进行发布。&lt;/p&gt;

&lt;p&gt;而以上的方式仅适用于测试环境的快速迭代，生产环境则采用 tag 的模式，针对不同的子项目，打不同前缀的 tag ，比如子项目为 test1 ，则打 &lt;code&gt;test1-v0.0.1&lt;/code&gt; 的 tag，就会对该子项目进行生产发布。&lt;/p&gt;

&lt;h3 id=&#34;构建效果&#34;&gt;构建效果&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;有修改的子项目&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ws1.sinaimg.cn/large/ad5fbf65gy1g6vm2ul2zfj21ky148jx0.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;无修改的子项目&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wx1.sinaimg.cn/large/ad5fbf65gy1g6vm49on4kj21jk11iaf7.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;kubernetes-发布状态检查&#34;&gt;Kubernetes 发布状态检查&lt;/h2&gt;

&lt;p&gt;之前的 Kubernetes 发布只是将服务发布到 Kubernetes 集群，并不管服务是否正常启动。针对这个问题以及我们的 Kubernetes 应用管理模式，我们开发了 drone 的 Kubernetes 发布插件，该插件包括 &lt;code&gt;kubectl&lt;/code&gt; 、&lt;code&gt;kustomize&lt;/code&gt;、&lt;code&gt;kubedog&lt;/code&gt; ，来完善我们的 Kubernetes 发布 step 。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;.drone.yml&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;steps:
- name: Kubernetes 部署
  image: guoxudongdocker/kubectl
  volumes:
  - name: kube
    path: /root/.kube
  settings:
    check: false                 # 该参数为是否开启子模块检查
    config: deploy/overlays/uat  # 这里使用 kustomize ,详细使用方法请见 https://github.com/kubernetes-sigs/kustomize
    timeout: 300                 # kubedog 的检测超时
    name: {your-deployment-name} # 如果开启子模块检查则需要填入子模块名称

...

volumes:
- name: kube
  host:
    path: /tmp/cache/.kube  # kubeconfig 挂载位置

trigger:
  branch:
  - master  # 触发 CI 的分支
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用该插件会如果为测试构建，则会自动设置 docker 镜像 tag 为 &lt;code&gt;DRONE_BUILD_NUMBER&lt;/code&gt; ；如果为生产构建（git tag），则叫自动设置 docker 镜像 tag 为 &lt;code&gt;DRONE_TAG&lt;/code&gt; ，然后通过 &lt;code&gt;kubectl apply -k .&lt;/code&gt; 进行部署，同时使用 &lt;code&gt;kubedog&lt;/code&gt; 进行部署状态检查，如果服务正常启动则该 step 通过，如果超时或者部署报错则该 step 失败。&lt;/p&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;根据我们目前的开发模式，对 drone 插件进行了全方位的开发。由于 dockerhub 的镜像拉取经常超时，则将镜像推送到了我们自己的镜像仓库；对钉钉通知也进行了优化；同时也根据我们目前的开发语言进行了插件的开发，提供了基于 Java 、Python 以及 Node.js 的 drone 插件，基本可以满足我们现在的 CI 需求，但随着 drone 的深入使用，越来越多的问题将会暴露出来。后续将会不断解决遇到的问题，持续优化。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>由一封邮件看 Mailing List 在开源项目中的重要性</title>
      <link>https://guoxudong.io/en/post/kubernetes-client-python/</link>
      <pubDate>Thu, 04 Jul 2019 09:16:41 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kubernetes-client-python/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;只要仔细找，想要的轮子总会有的。
&amp;mdash; 某不知名 DevOps 工程师&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;感谢 &lt;code&gt;kubernetes-dev&lt;/code&gt; 的 Mailing List ！早上在浏览邮件时发现了下面这封有趣的邮件：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wx3.sinaimg.cn/large/ad5fbf65gy1g4nkmrb8scj21780q0afv.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;接触 Kubernetes 也有不短的时间了，也见证了 Kubernetes 干掉 Swarm 和 Mesos 成为容器编排领域的事实标准的过程。在享受 Kubernetes 及其生态圈带来的便利的同时也在为 Kubernetes 及 CNCF 项目进行贡献。而使用 &lt;a href=&#34;https://github.com/kubernetes/kubectl&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;kubectl&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;https://github.com/rancher/rancher&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;rancher&lt;/code&gt;&lt;/a&gt; 甚至是 &lt;a href=&#34;https://github.com/IBM/kui&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;kui&lt;/code&gt;&lt;/a&gt; 这些 CLI 和 UI 工具对 Kubernetes 集群进行操作和观察。&lt;/p&gt;

&lt;p&gt;虽然上面这些工具为操作 Kubernetes 集群带来了极大的便利，但是归根到底还是一些开源项目，并不能满足我们的全部需求。所以我们只能根据我们自己的需求和 Kubernetes 的 api-server 进行定制，但是由于 Kubernetes 的 api-server 比较复杂，短时间内并不是那么好梳理的。&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-client-python&#34;&gt;kubernetes-client/python&lt;/h2&gt;

&lt;p&gt;由于我们自研的 DevOps 平台是使用 python 开发的，所以我也基于 python 语言开发了一套 Kubernetes Client ，但总的来说由于 Kubernetes 的功能实在太多，而我的开发实践并不是很多，开发出来的功能只是差强人意。&lt;/p&gt;

&lt;p&gt;而 &lt;a href=&#34;https://github.com/kubernetes-client/python&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;kubernetes-client/python&lt;/code&gt;&lt;/a&gt; 这个官方给出的轮子是真的香！&lt;/p&gt;

&lt;h3 id=&#34;安装方便&#34;&gt;安装方便&lt;/h3&gt;

&lt;p&gt;这个安装方式简单的令人发指，支持的 python 版本为 &lt;code&gt;2.7 | 3.4 | 3.5 | 3.6 | 3.7&lt;/code&gt; 并且和所有 python 依赖包一样，只需要使用 &lt;code&gt;pip&lt;/code&gt; 安装即可：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install kubernetes
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;简单示例&#34;&gt;简单示例&lt;/h3&gt;

&lt;p&gt;查看所有的 pod ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
#encoding: utf-8
#Author: guoxudong
from kubernetes import client, config

# Configs can be set in Configuration class directly or using helper utility
config.load_kube_config()

v1 = client.CoreV1Api()
print(&amp;quot;Listing pods with their IPs:&amp;quot;)
ret = v1.list_pod_for_all_namespaces(watch=False)
for i in ret.items:
    print(&amp;quot;%s\t%s\t%s&amp;quot; % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行查看结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Listing pods with their IPs:
172.22.1.126	kube-system	coredns-5975fdf55b-bqgkx
172.22.0.2	kube-system	coredns-5975fdf55b-vxbb4
10.16.16.13	kube-system	flexvolume-9ccf7
10.16.16.15	kube-system	flexvolume-h5xn2
10.16.16.14	kube-system	flexvolume-kvn5x
10.16.16.17	kube-system	flexvolume-mf4zv
10.16.16.14	kube-system	kube-proxy-worker-7lpfz
10.16.16.15	kube-system	kube-proxy-worker-9wd9s
10.16.16.17	kube-system	kube-proxy-worker-phbbj
10.16.16.13	kube-system	kube-proxy-worker-pst5d
172.22.1.9	kube-system	metrics-server-78b597d5bf-wdvqh
172.22.1.12	kube-system	nginx-ingress-controller-796ccc5d76-9jh5s
172.22.1.125	kube-system	nginx-ingress-controller-796ccc5d76-jwwwz
10.16.16.17	kube-system	terway-6mfs8
10.16.16.14	kube-system	terway-fz9ck
10.16.16.13	kube-system	terway-t9777
10.16.16.15	kube-system	terway-xbxlp
172.22.1.8	kube-system	tiller-deploy-5b5d8dd754-wpcrc
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;果然是一个好轮子，引入 kubeconfig 的方式及展示所有 namespace 的 pod 的方法封装的也十分简洁，是个非常漂亮的范例。建议可以看一下&lt;a href=&#34;https://github.com/kubernetes-client/python&#34; target=&#34;_blank&#34;&gt;源码&lt;/a&gt;，肯定会有收获的！&lt;/p&gt;

&lt;h3 id=&#34;支持版本&#34;&gt;支持版本&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;client-python&lt;/code&gt; 遵循 &lt;a href=&#34;https://semver.org/lang/zh-CN/&#34; target=&#34;_blank&#34;&gt;semver&lt;/a&gt; 规范，所以在 &lt;code&gt;client-python&lt;/code&gt; 的主要版本增加之前，代码将继续使用明确支持的 Kubernetes 集群版本。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Kubernetes 1.5&lt;/th&gt;
&lt;th&gt;Kubernetes 1.6&lt;/th&gt;
&lt;th&gt;Kubernetes 1.7&lt;/th&gt;
&lt;th&gt;Kubernetes 1.8&lt;/th&gt;
&lt;th&gt;Kubernetes 1.9&lt;/th&gt;
&lt;th&gt;Kubernetes 1.10&lt;/th&gt;
&lt;th&gt;Kubernetes 1.11&lt;/th&gt;
&lt;th&gt;Kubernetes 1.12&lt;/th&gt;
&lt;th&gt;Kubernetes 1.13&lt;/th&gt;
&lt;th&gt;Kubernetes 1.14&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;client-python 1.0&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 2.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 3.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 4.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 5.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 6.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 7.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 8.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 9.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python 10.0&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;client-python HEAD&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;mailing-list-的重要性&#34;&gt;Mailing List 的重要性&lt;/h2&gt;

&lt;p&gt;这次的收获很大程度得益于 &lt;code&gt;kubernetes-dev&lt;/code&gt; 的 Mailing List 也就是邮件列表。这种沟通方式在国内不是很流行，大家更喜欢使用 QQ 和微信这样的即时通讯软件进行交流，但是大多数著名开源项目都是主要使用 &lt;strong&gt;Mailing List&lt;/strong&gt; 进行交流，交流的数量甚至比在 GitHub issue 中还多，在与 Apache 、 CNCF 项目开源的贡献者和维护者交流中得知了使用 &lt;strong&gt;Mailing List&lt;/strong&gt; 主要考虑是一下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;这种异步的交流方式可以让更多关心该话题的开发人员一起加入到讨论中。&lt;/li&gt;
&lt;li&gt;mailing list 是永久保留的，如果你对某个话题感兴趣，可以随时回复邮件，关注这个话题的开发者都会收到邮件，无论这个话题是昨天提出的，还是去年提出的，有助于解决一些陈年老 BUG （俗称技术债）。&lt;/li&gt;
&lt;li&gt;即时通讯软件虽然很便利，但是问题很快会被评论顶掉，虽然诸如 slack 这样的工具解决了部分这方面的问题，但是还是不如 mailing list 好用。&lt;/li&gt;
&lt;li&gt;并不是所有地区的开发者都有高速的宽带，性能优秀的PC，在地球上很多地区还是只能使用拨号上网，网速只有几kb/s，他们甚至 GitHub issue 都无法使用。但是你不能剥夺他们参与开源项目的权利，而 mailing list 是一种很好的交流方式。&lt;/li&gt;
&lt;li&gt;通过 mailing list 可以很好掌握社区动态，效果明显好于 GitHub watch ，因为并不是项目的所有 commit 都是你关心的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;如果你有志于参与到开源运动，在享受开源软件带来便利的同事，还想为开源软件做出自己的贡献，那么 mailing list 是你进入社区最好的选择。在 mailing list 中和来自世界各地志同道合的开发者交流中提升自己的能力，创造更大的价值，迈出你参与开源运动的第一步。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（五）：配合 kubedog 完善 CI/CD 的最后一步</title>
      <link>https://guoxudong.io/en/post/kustomize-5/</link>
      <pubDate>Wed, 03 Jul 2019 15:20:31 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-5/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;在以往的 pipeline 中，使用 kubectl 进行部署 Deployment 后无法检查 Deployment 是否部署成功，只能通过使用命令/脚本来手动检查 Deployment 状态，而 kubedog 这个小工具完美解决了这个问题，完善了 CI/CD 流水线的最后一步。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;kubedog&#34;&gt;KubeDog&lt;/h2&gt;

&lt;p&gt;kubedog 是一个 lib 库和 CLI 小工具，允许在 CI/CD 部署 pipeline 中观察和跟踪 Kubernetes 资源。与 kustomize 配合，集成到 pipeline 之后，完美的解决了 CI/CD 的最后一步，完美的替代了之前不够灵活的脚本（好吧，其实我也开发了类似的小工具，但是有这么好用的轮子，拿来直接用何乐而不为呢？）。&lt;/p&gt;

&lt;p&gt;kubedog 提供了 lib 库和 CLI 小工具，这里由于是介绍 CI/CD 中的实践，所以只介绍其中的 &lt;code&gt;rollout track&lt;/code&gt; 功能。 lib 库的使用和 CLI 的 &lt;code&gt;follow&lt;/code&gt; 功能这里就不做介绍了，有兴趣的同学可以去 &lt;a href=&#34;https://github.com/flant/kubedog&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; 上查看该项目的各种使用方式。&lt;/p&gt;

&lt;h3 id=&#34;集成-kubedog&#34;&gt;集成 KubeDog&lt;/h3&gt;

&lt;p&gt;由于我司目前使用的是 &lt;a href=&#34;https://drone.io/&#34; target=&#34;_blank&#34;&gt;drone&lt;/a&gt; 进行 CI ，每个 step 都是由一个 docker 制作的插件组成。我制作了一个包含 &lt;code&gt;kubectl&lt;/code&gt; 、 &lt;code&gt;kustomize&lt;/code&gt; 和 &lt;code&gt;kubedog&lt;/code&gt; 的镜像。该镜像已上传 dockerhub ，需要的可以自行拉取使用 &lt;code&gt;guoxudongdocker/kubectl&lt;/code&gt; ,而该插件的使用也在 &lt;a href=&#34;https://github.com/sunny0826/kubectl-kustomize&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; 和 &lt;a href=&#34;https://cloud.docker.com/u/guoxudongdocker/repository/docker/guoxudongdocker/kubectl&#34; target=&#34;_blank&#34;&gt;DockerHub&lt;/a&gt; 上查看。&lt;/p&gt;

&lt;p&gt;而集成方式也比较简单，直接将 &lt;code&gt;kubectl&lt;/code&gt; 、 &lt;code&gt;kustomize&lt;/code&gt; 和 &lt;code&gt;kubedog&lt;/code&gt; 的可执行包下载到 &lt;code&gt;/usr/local/bin&lt;/code&gt; 并赋予执行权限即可，下面就是 &lt;code&gt;Dockerfile&lt;/code&gt; 文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;FROM alpine

LABEL maintainer=&amp;quot;sunnydog0826@gmail.com&amp;quot;

ENV KUBE_LATEST_VERSION=&amp;quot;v1.14.1&amp;quot;

RUN apk add --update ca-certificates \
 &amp;amp;&amp;amp; apk add --update -t deps curl \
 &amp;amp;&amp;amp; curl -L https://storage.googleapis.com/kubernetes-release/release/${KUBE_LATEST_VERSION}/bin/linux/amd64/kubectl -o /usr/local/bin/kubectl \
 &amp;amp;&amp;amp; chmod +x /usr/local/bin/kubectl \
 &amp;amp;&amp;amp; curl -L https://github.com/kubernetes-sigs/kustomize/releases/download/v2.0.3/kustomize_2.0.3_linux_amd64 -o /usr/local/bin/kustomize \
 &amp;amp;&amp;amp; chmod +x /usr/local/bin/kustomize \
 &amp;amp;&amp;amp; curl -L https://dl.bintray.com/flant/kubedog/v0.2.0/kubedog-linux-amd64-v0.2.0 -o /usr/local/bin/kubedog \
 &amp;amp;&amp;amp; chmod +x /usr/local/bin/kubedog \
 &amp;amp;&amp;amp; apk del --purge deps \
 &amp;amp;&amp;amp; rm /var/cache/apk/*


WORKDIR /root
ENTRYPOINT [&amp;quot;kubectl&amp;quot;]
CMD [&amp;quot;help&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kustomize-配合-kubedog-使用&#34;&gt;Kustomize 配合 KubeDog 使用&lt;/h2&gt;

&lt;p&gt;在镜像构建好之后就可以直接使用了，这里使用的是 DockerHub 的镜像仓库，这里建议将镜像同步到私有仓库，比如阿里云的容器镜像服务或者 Habor ，因为国内拉取 DockerHub 的镜像不太稳定，经常会拉取镜像失败或者访问超时，在 CI/CD 流水线中推荐使用更稳定镜像。&lt;/p&gt;

&lt;p&gt;以下是 &lt;code&gt;.drone.yml&lt;/code&gt; 示例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kind: pipeline
name: {your-pipeline-name}

steps:
- name: Kubernetes 部署
  image: guoxudongdocker/kubectl
  volumes:
  - name: kube
    path: /root/.kube
  commands:
    - cd deploy/overlays/dev    # 这里使用 kustomize ,详细使用方法请见 https://github.com/kubernetes-sigs/kustomize
    - kustomize edit set image {your-docker-registry}:${DRONE_BUILD_NUMBER}
    - kubectl apply -k . &amp;amp;&amp;amp; kubedog rollout track deployment {your-deployment-name} -n {your-namespace} -t {your-tomeout}

...

volumes:
- name: kube
  host:
    path: /tmp/cache/.kube  # kubeconfig 挂载位置

trigger:
  branch:
  - master  # 触发 CI 的分支
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的配置可见，在该 step 中执行了如下几步：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;进入 patch 所在路径&lt;/li&gt;
&lt;li&gt;使用了 Kustomize 命令 &lt;code&gt;kustomize edit set image {your-docker-registry}:${DRONE_BUILD_NUMBER}&lt;/code&gt; 方式将前面 step 中构建好的镜像的 tag 插入到 patch 中&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;kubectl apply -k .&lt;/code&gt; 进行 k8s 部署，要注意最后的那个 &lt;code&gt;.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;使用 kubedog 跟踪 Deployment 部署状态&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;命令解析：&lt;code&gt;kubedog rollout track deployment {your-deployment-name} -n {your-namespace} -t {your-tomeout}&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;deployment {your-deployment-name} : Deployment 的名称&lt;/li&gt;
&lt;li&gt;-n {your-namespace} : Deployment 所在的 namespace&lt;/li&gt;
&lt;li&gt;-t {your-tomeout} : 超时时间，单位为秒，超时后会报错，这里请根据实际部署情况进行设置&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;从 Kubernetes release v1.14 版本开始，&lt;code&gt;kustomize&lt;/code&gt; 集成到 &lt;code&gt;kubectl&lt;/code&gt; 中，越来越多 k8S 周边的小工具出现。这些小工具的出现帮助了 Kubernetes 的使用者来拉平 Kubernetes 的使用曲线，同时也标志着 K8S 的成熟，越来越多的开发人员基于使用 K8S 的痛点开发相关工具。套用一句今年 KubeCon 的 Keynote 演讲上，阿里云智能容器平台负责人丁宇的话： &lt;strong&gt;Kubernetes 正当时，云原生未来可期&lt;/strong&gt; 。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>记一次使用 Kustomize 时遇到的愚蠢问题</title>
      <link>https://guoxudong.io/en/post/kustomize-err-1/</link>
      <pubDate>Wed, 03 Jul 2019 13:44:50 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-err-1/</guid>
      <description>

&lt;h2 id=&#34;现象&#34;&gt;现象&lt;/h2&gt;

&lt;p&gt;在日常 CI/CD 流程中，已经将 Kustomize 集成到 pipeline 中使用，但是在对一个项目进行 Kustomize 改造时，将单个 &lt;code&gt;deploy.yaml&lt;/code&gt; 拆分为了若干个 patch 以达到灵活 Kubernetes 部署的目的。但是在使用 &lt;code&gt;kubectl apply -k .&lt;/code&gt; 命令进行部署的时候遇到了 &lt;code&gt;error: failed to find an object with apps_v1_Deployment|myapp to apply the patch&lt;/code&gt; 的报错。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://wx3.sinaimg.cn/large/ad5fbf65gy1g4mm1m3vx9j21oe10y102.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;解决之路&#34;&gt;解决之路&lt;/h2&gt;

&lt;p&gt;由于之前的使用中没有遇到此类报错，看报错信息像是 &lt;code&gt;apiVersion&lt;/code&gt; 的问题，所以先检查了所有 patch 的 &lt;code&gt;apiVersion&lt;/code&gt; ，但是并没有找到有什么问题。&lt;/p&gt;

&lt;h3 id=&#34;google-搜索&#34;&gt;Google 搜索&lt;/h3&gt;

&lt;p&gt;对该报错进行了搜索，搜索到如下结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ws4.sinaimg.cn/large/ad5fbf65gy1g4mmee8ctxj21900ns44c.jpg&#34; alt=&#34;image&#34; /&gt;
&lt;img src=&#34;https://wx4.sinaimg.cn/large/ad5fbf65gy1g4mmgrdz0fj21ou1b6wro.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;？？？ 为何这个 issue 没有解决就被提出者关闭了？&lt;/p&gt;

&lt;h3 id=&#34;问题解决&#34;&gt;问题解决&lt;/h3&gt;

&lt;p&gt;在 Google 了一圈之后还是没有找到什么有营养的回答，问题又回到了原点&amp;hellip;只能对所有的 patch 的每个字符和每个配置逐一进行了检查。结果发现是 &lt;code&gt;name&lt;/code&gt; 的内容 base 与 overlays 不同&amp;hellip; base 中是 &lt;code&gt;name:myapp&lt;/code&gt; ，而 overlays 中是 &lt;code&gt;name:my-app&lt;/code&gt; &amp;hellip;&lt;/p&gt;

&lt;p&gt;好吧，issue 关的是有道理的&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wx1.sinaimg.cn/large/ad5fbf65gy1g4mmuqm6n2j2098048a9z.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（四）：简述核心配置 kustomization.yaml</title>
      <link>https://guoxudong.io/en/post/kustomize-4/</link>
      <pubDate>Thu, 23 May 2019 12:50:12 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-4/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;在前面的文章中已经介绍了 kustomize 是什么，以及如何开始使用和如何简单的在 CI/CD 中使用，本篇文章将会介绍 kustomize 的核心文件 &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/zh/kustomization.yaml&#34; target=&#34;_blank&#34;&gt;kustomization.yaml&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;另外，博主已经向 kustomize 贡献了中文文档，已被官方采纳，现在在 kustomize 中的 &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/tree/master/docs/zh&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docs/zh&lt;/code&gt;&lt;/a&gt; 目录中就可看到，翻译的不好的地方欢迎指正。同时也在 GitHub 上新建了一个 名为 &lt;a href=&#34;https://github.com/sunny0826/kustomize-lab&#34; target=&#34;_blank&#34;&gt;kustomize-lab&lt;/a&gt; 的 repo 用于演示 kustomize 的各种用法及技巧，本文中介绍的内容也会同步更新到该 repo 中，欢迎 fork、star、PR。&lt;/p&gt;

&lt;h2 id=&#34;kustomization-yaml-的作用&#34;&gt;&lt;code&gt;kustomization.yaml&lt;/code&gt; 的作用&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Kustomize 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;有前面的文章&lt;a href=&#34;../kustomize-2&#34;&gt;《使用 Kustomize 帮你管理 kubernetes 应用（二）： Kustomize 的使用方法》&lt;/a&gt;中已经介绍了，每个 &lt;code&gt;base&lt;/code&gt; 或 &lt;code&gt;overlays&lt;/code&gt; 中都必须要有一个 &lt;code&gt;kustomization.yaml&lt;/code&gt;，这里我们看一下官方示例 &lt;code&gt;helloWorld&lt;/code&gt; 中的 &lt;code&gt;kustomization.yaml&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;commonLabels:
  app: hello

resources:
- deployment.yaml
- service.yaml
- configMap.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到该项目中包含3个 resources ， &lt;code&gt;deployment.yaml&lt;/code&gt;、&lt;code&gt;service.yaml&lt;/code&gt; 、 &lt;code&gt;configMap.yaml&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.
└── helloWorld
    ├── configMap.yaml
    ├── deployment.yaml
    ├── kustomization.yaml
    └── service.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;直接执行命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build helloWorld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以看到结果了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;apiVersion: v1
data:
  altGreeting: Good Morning!
  enableRisky: &amp;quot;false&amp;quot;
kind: ConfigMap
metadata:
  labels:
    app: hello
  name: the-map
image:
  caption: &amp;quot;Image from: [**Pexels**](https://www.pexels.com)&amp;quot;
  focal_point: &amp;quot;&amp;quot;
  preview_only: false
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hello
  name: the-service
spec:
  ports:
  - port: 8666
    protocol: TCP
    targetPort: 8080
  selector:
    app: hello
    deployment: hello
  type: LoadBalancer
image:
  caption: &amp;quot;Image from: [**Pexels**](https://www.pexels.com)&amp;quot;
  focal_point: &amp;quot;&amp;quot;
  preview_only: false
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: hello
  name: the-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hello
  template:
    metadata:
      labels:
        app: hello
        deployment: hello
    spec:
      containers:
      - command:
        - /hello
        - --port=8080
        - --enableRiskyFeature=$(ENABLE_RISKY)
        env:
        - name: ALT_GREETING
          valueFrom:
            configMapKeyRef:
              key: altGreeting
              name: the-map
        - name: ENABLE_RISKY
          valueFrom:
            configMapKeyRef:
              key: enableRisky
              name: the-map
        image: monopole/hello:1
        name: the-container
        ports:
        - containerPort: 8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的结果可以看大 kustomize 通过 &lt;code&gt;kustomization.yaml&lt;/code&gt; 将3个 resources 进行了处理，给三个 resources 添加了共同的 labels &lt;code&gt;app: hello&lt;/code&gt; 。这个示例展示了 &lt;code&gt;kustomization.yaml&lt;/code&gt; 的作用：&lt;strong&gt;将不同的 resources 进行整合，同时为他们加上相同的配置&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&#34;进阶使用&#34;&gt;进阶使用&lt;/h2&gt;

&lt;p&gt;上面只不过是一个简单的示例，下面将结合实际情况分享一些比较实用的用法&lt;/p&gt;

&lt;h3 id=&#34;根据环境生成不同配置&#34;&gt;根据环境生成不同配置&lt;/h3&gt;

&lt;p&gt;在实际的使用中，使用最多的就是为不同的环境配置不同的 &lt;code&gt;deploy.yaml&lt;/code&gt;，而使用 kustomize 可以把配置拆分为多个小的 patch ，然后通过 kustomize 来进行组合。而根据环境的不同，每个 patch 都可能不同，包括分配的资源、访问的方式、部署的节点都可以自由的定制。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.
├── flask-env
│   ├── README.md
│   ├── base
│   │   ├── deployment.yaml
│   │   ├── kustomization.yaml
│   │   └── service.yaml
│   └── overlays
│       ├── dev
│       │   ├── healthcheck_patch.yaml
│       │   ├── kustomization.yaml
│       │   └── memorylimit_patch.yaml
│       └── prod
│           ├── healthcheck_patch.yaml
│           ├── kustomization.yaml
│           └── memorylimit_patch.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里可以看到配置分为了 &lt;code&gt;base&lt;/code&gt; 和 &lt;code&gt;overlays&lt;/code&gt;， &lt;code&gt;overlays&lt;/code&gt; 则是继承了 &lt;code&gt;base&lt;/code&gt; 的配置，同时添加了诸如 healthcheck 和 memorylimit 等不同的配置，那么我们分别看一下 &lt;code&gt;base&lt;/code&gt; 和 &lt;code&gt;overlays&lt;/code&gt; 中 &lt;code&gt;kustomization.yaml&lt;/code&gt; 的内容&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;base&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;commonLabels:
app: test-cicd

resources:
- service.yaml
- deployment.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;base&lt;/code&gt; 中的 &lt;code&gt;kustomization.yaml&lt;/code&gt; 中定义了一些基础配置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;overlays&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;bases:
- ../../base
patchesStrategicMerge:
- healthcheck_patch.yaml
- memorylimit_patch.yaml
namespace: devops-dev
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;overlays&lt;/code&gt; 中的 &lt;code&gt;kustomization.yaml&lt;/code&gt; 则是基于 &lt;code&gt;base&lt;/code&gt; 新增了一些个性化的配置，来达到生成不同环境的目的。&lt;/p&gt;

&lt;p&gt;执行命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build flask-env/overlays/dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;apiVersion: v1
kind: Service
metadata:
  labels:
    app: test-cicd
  name: test-cicd
  namespace: devops-dev
spec:
  ports:
  - name: http
    port: 80
    targetPort: 80
  selector:
    app: test-cicd
  type: ClusterIP
image:
  caption: &amp;quot;Image from: [**Pexels**](https://www.pexels.com)&amp;quot;
  focal_point: &amp;quot;&amp;quot;
  preview_only: false
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: test-cicd
  name: test-cicd
  namespace: devops-dev
spec:
  replicas: 1
  selector:
    matchLabels:
      app: test-cicd
  template:
    metadata:
      labels:
        app: test-cicd
        version: 0.0.3
    spec:
      containers:
      - env:
        - name: ENV
          value: dev
        image: guoxudongdocker/flask-python:latest
        imagePullPolicy: Always
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 20
        name: test-cicd
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 20
        resources:
          limits:
            cpu: 300m
            memory: 500Mi
          requests:
            cpu: 300m
            memory: 500Mi
        volumeMounts:
        - mountPath: /etc/localtime
          name: host-time
      imagePullSecrets:
      - name: registry-pull-secret
      volumes:
      - hostPath:
          path: /etc/localtime
        name: host-time
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到包括 &lt;code&gt;replicas&lt;/code&gt;、&lt;code&gt;limits&lt;/code&gt;、&lt;code&gt;requests&lt;/code&gt;、&lt;code&gt;env&lt;/code&gt; 等 dev 中个性的配置都已经出现在了生成的 yaml 中。由于篇幅有限，这里没有把所有的配置有罗列出来，需要的可以去 &lt;a href=&#34;https://github.com/sunny0826/kustomize-lab&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; 上自取。&lt;/p&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;上面所有的 &lt;code&gt;kustomize build dir/&lt;/code&gt; 都可以使用 &lt;code&gt;kubectl apply -k dir/&lt;/code&gt; 实现，但是需要 &lt;code&gt;v14.0&lt;/code&gt; 版以上的 &lt;code&gt;kubectl&lt;/code&gt;，也就是说，其实我们在集成到 CI/CD 中的时候，甚至都不需要用来 &lt;code&gt;kustomize&lt;/code&gt; 命令集，有 &lt;code&gt;kubectl&lt;/code&gt; 就够了。&lt;/p&gt;

&lt;p&gt;由于篇幅有限，这里没法吧所有 &lt;code&gt;kustomization.yaml&lt;/code&gt; 的用途都罗列出来，不过可以在官方文档中找到我提交的中文翻译版 &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/zh/kustomization.yaml&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;kustomization.yaml&lt;/code&gt;&lt;/a&gt;，可以直接去官方 GitHub 查看。同时 &lt;a href=&#34;https://github.com/sunny0826/kustomize-lab&#34; target=&#34;_blank&#34;&gt;kustomize-lab&lt;/a&gt; 会持续更行，敬请关注。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>轻量快速的 CI 工具 Drone</title>
      <link>https://guoxudong.io/en/post/drone-ci/</link>
      <pubDate>Tue, 21 May 2019 08:59:00 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/drone-ci/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;公司之前一直在使用 Jenkins 作为 CI/CD 工具， Jenkins 非常强大，它完成了几乎所有 CI/CD 的工作，并且应用于整个团队有好长一段时间了。但是随着公司推荐数字化、智慧化，以及服务容器化的推进， Jenkins 的一些弊端也凸显了出来：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;重量级：&lt;/strong&gt; Jenkins 功能十分齐全，几乎可以做所有的事情。但是这也是他的一个弊端，过于重量级，有时候往往一个小的修改需要改动许多地方，升级\下载插件后需要进行重启等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;升级不易：&lt;/strong&gt; 在一些安全 Jenkins 相关的安全漏洞被公开后，我们会对 Jenkins 进行升级，但这也不是一件容易的事。之前就出现过升级\重启后，所有 job 丢失，虽然我们所有项目配置都是以 Jenkinsfile 的形式统一存储，但是每个 job 都需要重新重新创建，包括每个 job 的权限&amp;hellip;.._(´ཀ`」 ∠)_&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;权限控制复杂：&lt;/strong&gt; 这其实也是 Jenkins 的一大优势，可以精确控制每个用户的权限，但是需要花费更多时间去配置，时间长了也会出现权限混乱的问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;UI 界面：&lt;/strong&gt; 这个其实是吐槽最多的部分，虽然有诸如：Blue Ocean 这样的插件来展示 pipeline ，但是还是没有从根本改变它简陋的 UI 界面。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;那么为什么选择使用 Drone 呢？&lt;/p&gt;

&lt;p&gt;其实在 GitHub 上提交 PR 后，大部分开源项目都会使用 &lt;a href=&#34;http://travis-ci.org/&#34; target=&#34;_blank&#34;&gt;travis-ci&lt;/a&gt; 对提交的代码进行 CI 及检查，而如果是 Kubernetes 相关的项目，则会使用 &lt;a href=&#34;https://github.com/k8s-ci-robot&#34; target=&#34;_blank&#34;&gt;prow&lt;/a&gt; 进行 CI。但是 &lt;a href=&#34;http://travis-ci.org/&#34; target=&#34;_blank&#34;&gt;travis-ci&lt;/a&gt; 只能用于 GitHub ，在寻找类似项目的时候， Drone 进入了我的视野。&lt;/p&gt;

&lt;p&gt;大道至简。和 Jenkins 相比， Drone 就轻量的多了，从应用本身的安装部署到流水线的构建都简洁的多。由于是和源码管理系统相集成，所以 Drone 天生就省去了各种账户\权限的配置，直接与 gitlab 、 github 、 Bitbucket 这样的源码管理系统操作源代码的权限一致。正如它官网上写的那样：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Any Source Code Manager&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Drone integrates seamlessly with multiple source code management systems, including GitHub, GitHubEnterprise, Bitbucket, and GitLab.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Any Platform&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Drone natively supports multiple operating systems and architectures, including Linux x64, ARM, ARM64 and Windows x64.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Any Language&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Drone works with any language, database or service that runs inside a Docker container. Choose from thousands of public Docker images or provide your own.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Drone 天生支持任何源码管理工具、任何平台和任何语言。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;而写这篇文章的目的，并不是要吹捧这个工具有多么的好用，而是要总结在搭建 drone 和使用时候需要的各种坑，帮助读者绕过这些坑。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;声明&#34;&gt;声明&lt;/h2&gt;

&lt;p&gt;鉴于在使用 Drone CI 中，遇到的各种坑都和 Drone 的版本有关，这里首先声明我使用的 Drone 版本为&lt;code&gt;1.1&lt;/code&gt;，使用&lt;code&gt;0.8&lt;/code&gt;版本的同学请绕道。&lt;/p&gt;

&lt;h2 id=&#34;搭建-drone&#34;&gt;搭建 Drone&lt;/h2&gt;

&lt;p&gt;这里要说的就是在使用 drone 中遇到的第一个坑，在最初正准备搭建 drone 的时候 Google 了很多相关的 blog ，大部分 blog （包括某些 &lt;a href=&#34;https://medium.com/&#34; target=&#34;_blank&#34;&gt;medium.com&lt;/a&gt; 上面近期的英文 blog） 推荐的安装方式都是使用 &lt;code&gt;docker-compose&lt;/code&gt;，而无一例外的都失败了&amp;hellip;走投无路之下，我回到了&lt;a href=&#34;https://docs.drone.io/installation/&#34; target=&#34;_blank&#34;&gt;官网的文档&lt;/a&gt;，发现&lt;code&gt;1.0&lt;/code&gt;之后许多参数都发生了变化，并且官方推荐使用 docker 的方式运行 Drone。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;所以在使用任何开源软件之前都要去阅读它的文档，不要跟着一篇 blog 就开始了（包括我的），这样会少踩很多坑！！！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里以 gitlab 为例，展示网上版本启动参数和实际参数的不同：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;th&gt;各种blog&lt;/th&gt;
&lt;th&gt;官网文档&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;设置 Drone 的管理员&lt;/td&gt;
&lt;td&gt;DRONE_ADMIN=admin&lt;/td&gt;
&lt;td&gt;DRONE_USER_CREATE=username:admin,admin:true&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;设置GitLab的域名&lt;/td&gt;
&lt;td&gt;DRONE_GITLAB_URL&lt;/td&gt;
&lt;td&gt;DRONE_SERVER_HOST&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;GitLab的Application中的key&lt;/td&gt;
&lt;td&gt;DRONE_GITLAB_CLIENT&lt;/td&gt;
&lt;td&gt;DRONE_GITLAB_CLIENT_ID&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;GitLab的Application中的secret&lt;/td&gt;
&lt;td&gt;DRONE_GITLAB_SECRET&lt;/td&gt;
&lt;td&gt;DRONE_GITLAB_CLIENT_SECRET&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Drone 域名&lt;/td&gt;
&lt;td&gt;DRONE_HOST&lt;/td&gt;
&lt;td&gt;DRONE_GITLAB_SERVER&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;上面只是列举了部分官方文档和网上流产版本的不同，所以在使用之前一定要仔细阅读官方文档。下附运行 drone 的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run \
  --volume=/var/run/docker.sock:/var/run/docker.sock \
  --volume=/var/lib/drone:/data \
  --env=DRONE_GIT_ALWAYS_AUTH=false \
  --env=DRONE_GITLAB_SERVER={your-gitlab-url} \  # gitlab 的 URL
  --env=DRONE_GITLAB_CLIENT_ID={your-gitlab-applications-id} \  #GitLab的Application中的id
  --env=DRONE_GITLAB_CLIENT_SECRET={your-gitlab-applicati-secret} \ #GitLab的Application中的secret
  --env=DRONE_SERVER_HOST={your-drone-url} \    # drone 的URl
  --env=DRONE_SERVER_PROTO=http \
  --env=DRONE_TLS_AUTOCERT=false \
  --env=DRONE_USER_CREATE=username:{your-admin-username},admin:true \   # Drone的管理员
  --publish=8000:80 \
  --publish=443:443 \
  --restart=always \
  --detach=true \
  --name=drone \
  drone/drone:1.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;关于 &lt;code&gt;gitlab Application&lt;/code&gt; 的配置和 Drone 其他参数含义请参考&lt;a href=&#34;https://docs.drone.io/installation/gitlab/single-machine/&#34; target=&#34;_blank&#34;&gt;官方文档&lt;/a&gt;，这里只展示单节点办的运行方式。&lt;/p&gt;

&lt;h2 id=&#34;核心文件-drone-yml&#34;&gt;核心文件 &lt;code&gt;.drone.yml&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;要使用 Drone 只需在项目根创建一个 &lt;code&gt;.drone.yml&lt;/code&gt; 文件即可，这个是 Drone 构建脚本的配置文件，它随项目一块进行版本管理，开发者不需要额外再去维护一个配置脚本。其实现代 CI 程序都是这么做了，这个主要是相对于 Jekins 来说的。虽然 Jekins 也有插件支持，但毕竟还是需要配置。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;值得注意的事这个文件时 &lt;code&gt;.drone.yml&lt;/code&gt;，由于 Kubernetes 使用的多了，第一次创建了一个 &lt;code&gt;.drone.yaml&lt;/code&gt; 文件，导致怎么都获取不到配置&amp;hellip;_(´ཀ`」 ∠)_&amp;hellip; YAML 工程师石锤了&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里放一个 Java 的 .drone.yml ，这个项目是 fork 别人的项目用作演示，记得要修改 &lt;code&gt;deployment.yaml&lt;/code&gt; 中的镜像仓库地址修改为自己的私有仓库。&lt;/p&gt;

&lt;p&gt;示例项目源码：&lt;a href=&#34;https://github.com/sunny0826/pipeline-example-maven&#34; target=&#34;_blank&#34;&gt;https://github.com/sunny0826/pipeline-example-maven&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-YAML&#34;&gt;kind: pipeline
name: pipeline-example-maven

steps:
- name: Maven编译
  image: maven:3-jdk-7
  volumes:
  - name: cache
    path: /root/.m2
  commands:
    - mvn clean install

- name: 构建镜像  
  image: plugins/docker
  volumes:
  - name: docker
    path: /var/run/docker.sock
  settings:
    username: 
      from_secret: docker_user
    password: 
      from_secret: docker_pass
    repo: {your-repo}
    registry: {your-registry}
    tags: ${DRONE_BUILD_NUMBER}

- name: Kubernetes 部署
  image: guoxudongdocker/kubectl:v1.14.1 
  volumes:
  - name: kube
    path: /root/.kube
  commands:
    - sed -i &amp;quot;s/#Tag/${DRONE_BUILD_NUMBER}/g&amp;quot; deployment.yaml
    - kubectl apply -f deployment.yaml

- name: 钉钉通知
  image: guoxudongdocker/drone-dingtalk 
  settings:
    token: 
      from_secret: dingding
    type: markdown
    message_color: true
    message_pic: true
    sha_link: true
  when:
    status: [failure, success]

volumes:
- name: cache
  host:
    path: /tmp/cache/.m2
- name: kube
  host:
    path: /tmp/cache/.kube/.test_kube
- name: docker
  host:
    path: /var/run/docker.sock

trigger:
  branch:
  - master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;值得注意的事：上面的这个 &lt;code&gt;.drone.yml&lt;/code&gt; 文件将本地的&lt;code&gt;.m2&lt;/code&gt;文件、kubeconfig文件、&lt;code&gt;docker.sock&lt;/code&gt; 文件挂载到 pipeline 中以实现 maven 打包缓存，k8s 部署、docker 缓存的作用，以提高 CI 速度。而是用挂载需要管理员在项目 settings 中勾选 &lt;code&gt;Trusted&lt;/code&gt; ，这个操作只能管理员进行，普通用户是看不到这个选项的。而管理员就是在docker运行时候 &lt;code&gt;--env=DRONE_USER_CREATE=username:{your-admin-username},admin:true&lt;/code&gt; 设置的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tvax2.sinaimg.cn/large/ad5fbf65gy1g38qvifxwij21d40tk76s.jpg&#34; alt=&#34;WX20190521-104717@2x&#34; /&gt;&lt;/p&gt;

&lt;p&gt;而上传镜像和钉钉同时需要在 settings 设置中添加 secret&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;docker_user：docker 仓库用户名&lt;/li&gt;
&lt;li&gt;docker_pass：docker 仓库密码&lt;/li&gt;
&lt;li&gt;dingding： 钉钉机器人 token&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;注意这里的钉钉 token 是 webhook 中 &lt;code&gt;https://oapi.dingtalk.com/robot/send?access_token=&lt;/code&gt; 后这部分
&lt;img src=&#34;https://tvax2.sinaimg.cn/large/ad5fbf65gy1g38r1mkoztj20iy0ezgmg.jpg&#34; alt=&#34;WX20190521-105337&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://tvax2.sinaimg.cn/large/ad5fbf65gy1g38qxizsg1j21ia0tujtb.jpg&#34; alt=&#34;WX20190521-104942@2x&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;构建结果&#34;&gt;构建结果&lt;/h2&gt;

&lt;p&gt;添加 &lt;code&gt;.drone.yml&lt;/code&gt; 文件后，向 master 分支提交代码即可出发 CI 构建&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wx3.sinaimg.cn/large/ad5fbf65gy1g38r68yb8pj21l40sawit.jpg&#34; alt=&#34;WX20190521-105809@2x&#34; /&gt;&lt;/p&gt;

&lt;p&gt;CI 结束后，会在钉钉机器人所在群收到通知&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tvax2.sinaimg.cn/large/ad5fbf65gy1g38r8cttcrj20e90bzacr.jpg&#34; alt=&#34;WX20190521-110009&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;插件支持&#34;&gt;插件支持&lt;/h2&gt;

&lt;p&gt;可以看到，每一步的镜像都是一个镜像，上面 pipeline 中的 Kubernetes 及钉钉通知插件就是我开发的，具体开发方法可以参考&lt;a href=&#34;https://docs.drone.io/&#34; target=&#34;_blank&#34;&gt;官方文档&lt;/a&gt;，而官方也提供了许多&lt;a href=&#34;http://plugins.drone.io/&#34; target=&#34;_blank&#34;&gt;官方插件&lt;/a&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;构建后部署：&lt;a href=&#34;http://plugins.drone.io/mactynow/drone-kubernetes/&#34; target=&#34;_blank&#34;&gt;Kubernetes&lt;/a&gt;、&lt;a href=&#34;http://plugins.drone.io/ipedrazas/drone-helm/&#34; target=&#34;_blank&#34;&gt;helm&lt;/a&gt;、&lt;a href=&#34;http://plugins.drone.io/appleboy/drone-scp/&#34; target=&#34;_blank&#34;&gt;scp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;构建后通知：&lt;a href=&#34;http://plugins.drone.io/lddsb/drone-dingtalk-message/&#34; target=&#34;_blank&#34;&gt;钉钉&lt;/a&gt; 、&lt;a href=&#34;http://plugins.drone.io/drillster/drone-email/&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt;、&lt;a href=&#34;http://plugins.drone.io/drone-plugins/drone-slack/&#34; target=&#34;_blank&#34;&gt;Slack&lt;/a&gt;、&lt;a href=&#34;http://plugins.drone.io/lizheming/drone-wechat/&#34; target=&#34;_blank&#34;&gt;微信&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;后记&#34;&gt;后记&lt;/h2&gt;

&lt;p&gt;Drone 整体用起来还是很方便的，搭建、上手速度都很快，但是官方文档给的不够详实，而网上充斥着各种各样0.8版本的的实例，但是其实官网早就发布了1.0版本，而官方并没有 &lt;code&gt;example&lt;/code&gt; 这样的示例项目，这样就又把本来降下来的学习曲线拉高了。许多坑都需要自己去趟，我在测试 drone 的时候，就构构建了上百次，不停的修改 &lt;code&gt;.drone.yml&lt;/code&gt; ， commit 信息看起来是很恐怖的。后续抽空会向官方贡献 &lt;code&gt;example&lt;/code&gt; 这样的 PR。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（三）：将 Kustomize 应用于 CI/CD</title>
      <link>https://guoxudong.io/en/post/kustomize-3/</link>
      <pubDate>Mon, 06 May 2019 16:46:28 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-3/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;首先明确软件版本，我这里使用的是 &lt;code&gt;Jenkins ver. 2.121.3&lt;/code&gt; ，这个版本比较老，其上安装 Kubernetes 插件所使用 &lt;code&gt;kubectl&lt;/code&gt; 版本也比较老，&lt;strong&gt;无法使用&lt;/strong&gt; Kustomize 的 yaml 文件需要的 &lt;code&gt;apiVersion: apps/v1&lt;/code&gt; ，直接使用生成 &lt;code&gt;deploy.yaml&lt;/code&gt; 文件会报错，所以这里选择了自己构建一个包含 &lt;code&gt;kubectl&lt;/code&gt; 和 &lt;code&gt;kustomize&lt;/code&gt; 的镜像，在镜像中使用 Kustomize 生成所需 yaml 文件并在 Kubernetes 上部署。&lt;/p&gt;

&lt;h2 id=&#34;软件版本&#34;&gt;软件版本&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;软件&lt;/th&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Jenkins&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://jenkins.io/&#34; target=&#34;_blank&#34;&gt;2.121.3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;kubectl&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34; target=&#34;_blank&#34;&gt;v1.14.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;kustomize&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/releases&#34; target=&#34;_blank&#34;&gt;v2.0.3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;前期准备&#34;&gt;前期准备&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Jenkins ：本篇使用 Jenkins 演示 CI/CD ，安装 Jenkins 就不在赘述，可以使用多种方法安装 Jenkins ，详细方法见&lt;a href=&#34;https://jenkins.io&#34; target=&#34;_blank&#34;&gt;官网&lt;/a&gt;。同时。 CI/CD 的工具有很多，这里为了省事使用笔者现有的 Jenkins 进行演示，&lt;strong&gt;不推荐&lt;/strong&gt;使用同笔者一样的版本，请使用较新的版本；同时也可以使用其他 CI/CD 工具，这里推荐使用 &lt;a href=&#34;https://drone.io/&#34; target=&#34;_blank&#34;&gt;drone&lt;/a&gt;。如果有更好的方案，欢迎交流，可以在&lt;a href=&#34;https://blog.maoxianplay.com/contact/&#34; target=&#34;_blank&#34;&gt;关于&lt;/a&gt;中找到我的联系方式。&lt;/li&gt;

&lt;li&gt;&lt;pre&gt;&lt;code class=&#34;language-kubectl```&#34;&gt;- Web 应用：这里使用 flask 写了一个简单的 web 应用，用于演示，同样以上传 dockerhub [```guoxudongdocker/flask-python```](https://hub.docker.com/r/guoxudongdocker/flask-python)

## 目录结构

首先看一下目录结构，目录中包括 ```Dockerfile``` 、 ```Jenkinsfile``` 、 Kustomize 要使用的 ```deploy``` 目录以及 web 应用目录。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bush&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;.
├── Dockerfile
├── Jenkinsfile
├── app
│   ├── main.py
│   └── uwsgi.ini
└── deploy
    ├── base
    │   ├── deployment.yaml
    │   ├── kustomization.yaml
    │   └── service.yaml
    └── overlays
        ├── dev
        │   ├── healthcheck_patch.yaml
        │   ├── kustomization.yaml
        │   └── memorylimit_patch.yaml
        └── prod
            ├── healthcheck_patch.yaml
            ├── kustomization.yaml
            └── memorylimit_patch.yaml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
这里可以看到 overlays 总共有两个子目录 `dev` 和 `prod` ，分别代表不同环境，在不同的环境中，应用不同的配置。

## Jenkins 配置

Jenkins 的配置相对简单，只需要新建一个 pipeline 类型的 job

![WX20190506-180159](https://wx4.sinaimg.cn/large/ad5fbf65gy1g2rr57oixbj20tn0ogq6v.jpg)

增加参数化构建，**注**：参数化构建需要安装 Jenkins 插件

![WX20190506-180918](https://ws4.sinaimg.cn/large/ad5fbf65gy1g2rrcb5ic9j21470q7mz8.jpg)

然后配置代码仓库即可

![WX20190507-094958](https://ws3.sinaimg.cn/large/ad5fbf65gy1g2sij1xlb2j214w0nw0uw.jpg)

## Pipeline 

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;groovy
podTemplate(label: &amp;lsquo;jnlp-slave&amp;rsquo;, cloud: &amp;lsquo;kubernetes&amp;rsquo;,
  containers: [
    containerTemplate(
        name: &amp;lsquo;jnlp&amp;rsquo;,
        image: &amp;lsquo;guoxudongdocker/jenkins-slave&amp;rsquo;,
        alwaysPullImage: true
    ),
    containerTemplate(name: &amp;lsquo;kubectl&amp;rsquo;, image: &amp;lsquo;guoxudongdocker/kubectl:v1.14.1&amp;rsquo;, command: &amp;lsquo;cat&amp;rsquo;, ttyEnabled: true),
  ],
  nodeSelector:&amp;lsquo;ci=jenkins&amp;rsquo;,
  volumes: [
    hostPathVolume(mountPath: &amp;lsquo;/var/run/docker.sock&amp;rsquo;, hostPath: &amp;lsquo;/var/run/docker.sock&amp;rsquo;),
    hostPathVolume(mountPath: &amp;lsquo;/usr/bin/docker&amp;rsquo;, hostPath: &amp;lsquo;/usr/bin/docker&amp;rsquo;),
    hostPathVolume(mountPath: &amp;lsquo;/usr/local/jdk&amp;rsquo;, hostPath: &amp;lsquo;/usr/local/jdk&amp;rsquo;),
    hostPathVolume(mountPath: &amp;lsquo;/usr/local/maven&amp;rsquo;, hostPath: &amp;lsquo;/usr/local/maven&amp;rsquo;),
    secretVolume(mountPath: &amp;lsquo;/home/jenkins/.kube&amp;rsquo;, secretName: &amp;lsquo;devops-ctl&amp;rsquo;),
  ],
)
{
    node(&amp;ldquo;jnlp-slave&amp;rdquo;){
        stage(&amp;lsquo;Git Checkout&amp;rsquo;){
            git branch: &amp;lsquo;${branch}&amp;rsquo;, url: &amp;lsquo;&lt;a href=&#34;https://github.com/sunny0826/flask-python.git&#39;&#34; target=&#34;_blank&#34;&gt;https://github.com/sunny0826/flask-python.git&#39;&lt;/a&gt;
        }
        stage(&amp;lsquo;Build and Push Image&amp;rsquo;){
            withCredentials([usernamePassword(credentialsId: &amp;lsquo;docker-register&amp;rsquo;, passwordVariable: &amp;lsquo;dockerPassword&amp;rsquo;, usernameVariable: &amp;lsquo;dockerUser&amp;rsquo;)]) {
                sh &amp;ldquo;&amp;rsquo;
                docker login -u ${dockerUser} -p ${dockerPassword}
                docker build -t guoxudongdocker/flask-python:${Tag} .
                docker push guoxudongdocker/flask-python:${Tag}
                &amp;ldquo;&amp;rsquo;
            }
        }
        stage(&amp;lsquo;Deploy to K8s&amp;rsquo;){
            if (&amp;lsquo;true&amp;rsquo; == &amp;ldquo;${deploy}&amp;rdquo;) {
                container(&amp;lsquo;kubectl&amp;rsquo;) {
                    sh &amp;ldquo;&amp;rsquo;
                    cd deploy/base
                    kustomize edit set image guoxudongdocker/flask-python:${Tag}
                    &amp;ldquo;&amp;rsquo;
                    echo &amp;ldquo;部署到 Kubernetes&amp;rdquo;
                    if (&amp;lsquo;prod&amp;rsquo; == &amp;ldquo;${ENV}&amp;rdquo;) {
                        sh &amp;ldquo;&amp;rsquo;
                        # kustomize build deploy/overlays/prod | kubectl apply -f -
                        kubectl applt -k deploy/overlays/prod
                        &amp;ldquo;&amp;rsquo;
                    }else {
                        sh &amp;ldquo;&amp;rsquo;
                        # kustomize build deploy/overlays/dev | kubectl apply -f -
                        kubectl applt -k deploy/overlays/dev
                        &amp;ldquo;&amp;rsquo;
                    }	
                }
            }else{
                echo &amp;ldquo;跳过Deploy to K8s&amp;rdquo;
            }&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
这里要注意几点：

- 拉取 git 中的代码需要在 jenkins 中配置凭据。
- 笔者的 jenkins 部署在 Kubernetes 上，要操作集群的话，需要将 kubeconfig 以 Secret 的形式挂载到 jenkins 所在 namespace。
- `jenkins-slave` 需要 Java 环境运行，所以要将宿主机的 `jdk` 挂载到 `jenkins-slave` 中。
- 同样的，宿主机中需要事先安装 `docker`。
- `docker-register` 为 dockerhub 的登录凭证，需要在 jenkins 中添加相应的凭证。

## 演示

image:
  caption: &amp;quot;Image from: [**Pexels**](https://www.pexels.com)&amp;quot;
  focal_point: &amp;quot;&amp;quot;
  preview_only: false
---

### 开始构建

这里选择环境、分支，填入版本即可开始构建，**注意：**这里的版本将已 tag 的形式标记 docker 镜像。

![WX20190507-095142](https://ws2.sinaimg.cn/large/ad5fbf65gy1g2sikst7tuj20ob0evabw.jpg)

这里就可以看到构建成功了

![WX20190507-103721](https://ws2.sinaimg.cn/large/ad5fbf65ly1g2sjw9w22ej20v80km0w3.jpg)

### 查看结果

这里为了方便（其实就是懒），我就不给这个服务添加 ingress 来从外部访问了，这里使用 [KT](https://yq.aliyun.com/articles/690519) 打通本地和 k8s 集群网络来进行调试。

&amp;gt;为了简化在Kubernetes下进行联调测试的复杂度，云效在SSH隧道网络的基础上并结合Kubernetes特性构建了一款面向开发者的辅助工具kt

这里看到这个服务正常启动了

![WX20190507-104154](https://ws2.sinaimg.cn/large/ad5fbf65ly1g2sk11dnzxj20av027jrn.jpg)

### 发布新版本

更新 web 服务并提交

![WX20190507-104936](https://ws4.sinaimg.cn/large/ad5fbf65gy1g2sk94v1c5j209702vwej.jpg)


按照上面步骤在 jenkins 中重新构建，当然也可以配置钩子，每次代码提交后自动构建

### 查看查看新版本

同上面一样，在构建成功后查看服务是否更新

![WX20190507-105539](https://wx4.sinaimg.cn/large/ad5fbf65gy1g2skfczaz4j20by01smx7.jpg)

可以看到，版本已经更新了

### 发布生产环境

这里模拟一下发布生产环境，假设生产环境是在 `devops-prod` 的 namespace 中，这里只做演示之用，真正的生产环境中，可能存在不止一个 k8s 集群，这时需要修改 Jenkinsfile 中的 `secretVolume` 来挂载不同 k8s 的 kubeconfig 来达到发布到不同集群的目的。当然，一般发布生产环境只需选择测试通过的镜像来发布即可，不需要在进行构建打包。

![WX20190507-110730](https://ws3.sinaimg.cn/large/ad5fbf65gy1g2skrnbjyuj20fc0bjmxp.jpg)

### 查看生产版本

![WX20190507-110850](https://ws1.sinaimg.cn/large/ad5fbf65ly1g2skt3rp4yj20aq010glj.jpg)

### 总结

上面的这些步骤简单的演示了使用 jenkins 进行 CI/CD 的流程，流程十分简单，这里仅供参考

## Kustomize 的作用

那么， Kustomize 在整个流程中又扮演了一个什么角色呢？

### 更新镜像

在 `jenkinsfile` 中可以看到， kustomize 更新了基础配置的镜像版本，这里我们之前一直是使用 `sed -i &amp;quot;s/#Tag/${Tag}/g&amp;quot; deploy.yaml` 来进行替换了，但是不同环境存在比较多的差异，需要替换的越来越多，导致 Jekninsfile 也越来越臃肿和难以维护。 kustomize 解决了这个问题。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bash
kustomize edit set image guoxudongdocker/flask-python:${Tag}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
### 环境区分

上面也提到了，不同的环境我们存在这许多差异，虽然看上去大致类似，但是很多细节都需要修改。这时 kustomize 就起到了很大的作用，不同环境相同的配置都放在 `base` 中，而差异就可以在 `overlays` 中实现。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bash
.
├── base
│   ├── deployment.yaml
│   ├── kustomization.yaml
│   └── service.yaml
└── overlays
    ├── dev
    │   ├── healthcheck_patch.yaml
    │   ├── kustomization.yaml
    │   └── memorylimit_patch.yaml
    └── prod
        ├── healthcheck_patch.yaml
        ├── kustomization.yaml
        └── memorylimit_patch.yaml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;可以看到， `base` 中维护了项目共同的基础配置，如果有镜像版本等基础配置需要修改，可以使用 `kustomize edit set image ...` 来直接修改基础配置，而真正不同环境，或者不同使用情况的配置则在 `overlays` 中 以 patch 的形式添加配置。这里我的配置是 prod 环境部署的副本为2，同时给到的资源也更多，详情可以在 [Github](https://github.com/sunny0826/flask-python) 上查看。

### 与 kubectl 的集成

在 jenkinsfile 中可以看到

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bash&lt;/p&gt;

&lt;h1 id=&#34;kustomize-build-deploy-overlays-dev-kubectl-apply-f&#34;&gt;kustomize build deploy/overlays/dev | kubectl apply -f -&lt;/h1&gt;

&lt;p&gt;kubectl apply -k deploy/overlays/dev
```&lt;/p&gt;

&lt;p&gt;这两条命令的执行效果是一样的，在 &lt;code&gt;kubectl v1.14.0&lt;/code&gt; 以上的版本中，已经集成了 kustomize ，可以直接使用 &lt;code&gt;kubectl&lt;/code&gt; 进行部署。&lt;/p&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;这里只是对 kustomize 在 CI/CD 中简单应用的展示，只是一种比较简单和基础的使用，真正的 CI 流程要比这个复杂的多，这里只是为了演示 kustomize 的使用而临时搭建的。而 kustomize 还有很多黑科技的用法，将会在后续的文章中介绍。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>炫酷的终端软件 eDEX-UI</title>
      <link>https://guoxudong.io/en/post/edex-ui/</link>
      <pubDate>Mon, 29 Apr 2019 11:55:47 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/edex-ui/</guid>
      <description>

&lt;p&gt;马上就是五一假期了，而且今年的五一假期有4天！想必大家已经安排好是在家写代码还是出门去冒险了。不过在五一假期之前，我这里推荐一个好玩的又好用的软件给大家。&lt;/p&gt;

&lt;p&gt;想必大部分朋友和我一样在上周去看了复联4，其中钢铁侠战衣及设备各种炫酷又极具科技感的操作界面一定让你记忆犹新。很多朋友可能和我一样，都希望拥有一套这样的操作界面，这样不管是工作还是学习都会变得有趣而高效（主要是炫酷）。其实很早以前我就尝试写过，但是由于技术有限，写出来的工具都不是很符合我的要求，渐渐的也就都废弃了。而今天要介绍的这个软件，完全符合我的要求，高端大气上档次，并且还是开源的。&lt;/p&gt;

&lt;h2 id=&#34;edex-ui&#34;&gt;eDEX-UI&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/GitSquared/edex-ui&#34; target=&#34;_blank&#34;&gt;eDEX-UI&lt;/a&gt; 是一个全屏且跨平台、可定制的终端模拟器，具有先进的监控和触摸屏支持。它的外观类似科幻的计算机界面。在保持未来感的外观和感觉的同时，它努力保持一定的功能水平并可用于现实场景，其更大的目标是将科幻用户体验纳入主流。&lt;/p&gt;

&lt;h3 id=&#34;特性&#34;&gt;特性&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;功能齐全的终端仿真器，带有选项卡、颜色、模拟鼠标，并支持 curses 和类似 curses的应用程序。&lt;/li&gt;
&lt;li&gt;实时系统（CPU、RAM、进程）和网络（GeoIP、活动连接、传输速率）监控。&lt;/li&gt;
&lt;li&gt;完全支持触摸屏，包括屏幕键盘。&lt;/li&gt;
&lt;li&gt;具备跟随终端 CWD（当前工作目录）的目录查看器。&lt;/li&gt;
&lt;li&gt;包括主题、屏幕键盘布局、CSS 注入等在内的高级自定义。&lt;/li&gt;
&lt;li&gt;由才华横溢的声音设计师制作的可选音效，可实现最佳的好莱坞黑客氛围。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;显示&#34;&gt;显示&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://yqfile.alicdn.com/b959597643a41c4b83e697307877082124c360d4.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里我使用了 &lt;code&gt;tron-disrupted&lt;/code&gt; 主题，还有多种主题可以选择&lt;/p&gt;

&lt;p&gt;可以看到这里的界面十分炫酷，可以为有些乏味的 shell 操作增添一抹乐趣&lt;/p&gt;

&lt;h3 id=&#34;配置&#34;&gt;配置&lt;/h3&gt;

&lt;p&gt;eDEX-UI 可以通过 &lt;code&gt;settings.json&lt;/code&gt; 文件进行配置，配置包括执行的 shell 类型、工作目录、键盘类型、主题等&lt;/p&gt;

&lt;p&gt;&lt;code&gt;settings.json&lt;/code&gt; 在 Mac 系统中，存放在 &lt;code&gt;/Users/guoxudong/Library/Application Support/eDEX-UI&lt;/code&gt; 中，默认的工作目录也是这个路径&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wx3.sinaimg.cn/large/ad5fbf65gy1g2jflhunukj21h30tck0r.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里可以看到我选择使用 &lt;code&gt;zsh&lt;/code&gt; 和 &lt;code&gt;tron-disrupted&lt;/code&gt; 主题，并将工作目录改为了我的用户空间&lt;/p&gt;

&lt;h2 id=&#34;局限&#34;&gt;局限&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;目前看来该软件的全平台支持是不错的，同时还支持触摸屏操作，但是目前还未测试在 pad 上使用，测试之后会在后续文章中补充&lt;/li&gt;
&lt;li&gt;CPU 占用过高，该软件 CPU 占用很高，如果是配置一般的电脑不建议让其作为终端常驻，偶尔拿出来玩玩即可&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（二）： Kustomize 的使用方法</title>
      <link>https://guoxudong.io/en/post/kustomize-2/</link>
      <pubDate>Fri, 19 Apr 2019 16:05:02 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-2/</guid>
      <description>

&lt;p&gt;本文介绍使用和维护 Kustomize 的方法及步骤。&lt;/p&gt;

&lt;h2 id=&#34;定制配置&#34;&gt;定制配置&lt;/h2&gt;

&lt;p&gt;在这个工作流方式中，所有的配置文件（ YAML 资源）都为用户所有，存在于私有 repo 中。其他人是无法使用的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://wx4.sinaimg.cn/large/ad5fbf65gy1g2813d1ia7j20qo0f0dgk.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;创建一个目录用于版本控制&lt;/p&gt;

&lt;p&gt;我们希望将一个名为 &lt;strong&gt;&lt;em&gt;ldap&lt;/em&gt;&lt;/strong&gt; 的 Kubernetes 集群应用的配置保存在自己的 repo 中。
这里使用 &lt;code&gt;git&lt;/code&gt; 进行版本控制。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git init ~/ldap
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;创建一个 &lt;code&gt;base&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/ldap/base
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在这个目录中创建并提交 &lt;code&gt;kustomization.yaml&lt;/code&gt; 文件和一组资源，例如 &lt;code&gt;deployment.yaml&lt;/code&gt; &lt;code&gt;service.yaml&lt;/code&gt; 等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;创建 &lt;code&gt;overlays&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/ldap/overlays/staging
mkdir -p ~/ldap/overlays/production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每个目录都需要一个 &lt;code&gt;kustomization.yaml&lt;/code&gt; 文件以及一个或多个 &lt;code&gt;patch&lt;/code&gt; ，例如 &lt;code&gt;healthcheck_patch.yaml&lt;/code&gt; &lt;code&gt;memorylimit_patch.yaml&lt;/code&gt; 等。。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-staging```&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;production&lt;code&gt;目录则可能会在&lt;/code&gt;deployment``` 中增加在副本数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;生成 &lt;code&gt;variants&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;运行 &lt;code&gt;kustomize&lt;/code&gt; ，将生成的配置用于 kubernetes 应用部署&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build ~/ldap/overlays/staging | kubectl apply -f -
kustomize build ~/ldap/overlays/production | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 kubernetes 1.14 版本， &lt;code&gt;kustomize&lt;/code&gt; 已经集成到 &lt;code&gt;kubectl&lt;/code&gt; 命令中，成为了其一个子命令，可使用 &lt;code&gt;kubectl&lt;/code&gt; 来进行部署&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl apply -k ~/ldap/overlays/staging
kubectl apply -k ~/ldap/overlays/production
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;使用现成的配置&#34;&gt;使用现成的配置&lt;/h2&gt;

&lt;p&gt;在这个工作流方式中，可从别人的 repo 中 fork kustomize 配置，并根据自己的需求来配置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://wx4.sinaimg.cn/large/ad5fbf65gy1g281xyfebej20qo0f0dgr.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过 fork/modify/rebase 等方式获得配置&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;将其克隆为你自己的 &lt;code&gt;base&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在这个 &lt;code&gt;bash&lt;/code&gt; 目录维护在一个 repo 中，在这个例子使用 &lt;code&gt;ladp&lt;/code&gt; 的 repo&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir ~/ldap
git clone https://github.com/$USER/ldap ~/ldap/base
cd ~/ldap/base
git remote add upstream git@github.com:$USER/ldap
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;创建 &lt;code&gt;overlays&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如上面的案例一样，创建并完善 &lt;code&gt;overlays&lt;/code&gt; 目录中的内容&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/ldap/overlays/staging
mkdir -p ~/ldap/overlays/production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用户可以将 &lt;code&gt;overlays&lt;/code&gt; 维护在不同的 repo 中&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;生成 &lt;code&gt;variants&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build ~/ldap/overlays/staging | kubectl apply -f -
kustomize build ~/ldap/overlays/production | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 kubernetes 1.14 版本， &lt;code&gt;kustomize&lt;/code&gt; 已经集成到 &lt;code&gt;kubectl&lt;/code&gt; 命令中，成为了其一个子命令，可使用 &lt;code&gt;kubectl&lt;/code&gt; 来进行部署&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl apply -k ~/ldap/overlays/staging
kubectl apply -k ~/ldap/overlays/production
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;（可选）更新 &lt;code&gt;base&lt;/code&gt;
用户可以定期从上游 repo 中 &lt;code&gt;rebase&lt;/code&gt; 他们的 &lt;code&gt;base&lt;/code&gt; 以保证及时更新&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/ldap/base
git fetch upstream
git rebase upstream/master
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/workflows.md&#34; target=&#34;_blank&#34;&gt;kustomize workflows - github.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kustomize: 无需模板定制你的 kubernetes 配置</title>
      <link>https://guoxudong.io/en/post/introducing-kustomize-template-free-configuration-customization-for-kubernetes/</link>
      <pubDate>Mon, 15 Apr 2019 17:23:21 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/introducing-kustomize-template-free-configuration-customization-for-kubernetes/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;作者：Jeff Regan (Google), Phil Wittrock (Google) 2018-05-29&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果你在运行 kubernetes 集群，你可能会拷贝一些包含 kubernetes API 对象的 YAML 文件，并且根据你的需求来修改这些文件，通过这些 YAML 文件来定义你的 kubernetes 配置。&lt;/p&gt;

&lt;p&gt;但是这种方法存在很难找到配置的源头并对其进行改进。今天 Google 宣布推出 &lt;strong&gt;Kustomize&lt;/strong&gt; ，一个作为 &lt;a href=&#34;https://github.com/kubernetes/community/tree/master/sig-cli&#34; target=&#34;_blank&#34;&gt;SIG-CLI&lt;/a&gt; 子项目的命令行工具。这个工具提供了一个全新的、纯粹的声明式的方法来定制 kubernetes 配置，遵循并利用我们熟悉且精心设计的 Kubernetes API。&lt;/p&gt;

&lt;p&gt;有这样一个常见的场景，在互联网上可以看到别人的 CMS（content management system，内容管理系统）的 kubernetes 配置，这个配置是一组包括 Kubernetes API 对象的 YAML 描述文件。然后，在您自己公司的某个角落，您找到一个你非常了解的数据库，希望用它来该 CMS 的数据。&lt;/p&gt;

&lt;p&gt;你希望同时使用它们，此外，你希望自定义配置文件以便你的资源实例在集群中显示，并通过添加一个标签来区分在同一集群中做同样事情的其他资源。同时也希望为其配置适当的 CPU 、内存和副本数。&lt;/p&gt;

&lt;p&gt;此外，你还想要配置整个配置的多种变化：一个专门用于测试和实验的小服务实例（就计算资源而言），或更大的用于对外提供服务的生产级别的服务实例。同时，其他的团队也希望拥有他们自己的服务实例。&lt;/p&gt;

&lt;h2 id=&#34;定制就是复用&#34;&gt;定制就是复用&lt;/h2&gt;

&lt;p&gt;kubernetes 的配置并不是代码（是使用 YAML 描述的 API 对象，严格来说应该是数据），但是配置的生命周期与代码的生命周期有许多相似之处。&lt;/p&gt;

&lt;p&gt;你需要在版本控制中保留配置。所有者的配置不必与使用者的配置相同。配置可以作为整体的一部分。而用户希望为在不同的情况下复用这些配置。&lt;/p&gt;

&lt;p&gt;与代码复用相同，一种复用配置的方法是简单的全部拷贝并进行自定义。像代码一样，切断与源代码的联系使得从改进变的十分困难。许多团队和环境都使用这种方法，每个团队和环境都拥有自己的配置，这使得简单的升级变得十分棘手。&lt;/p&gt;

&lt;p&gt;另一种复用方法是将源代码抽象为参数化模板。使用一个通过执行脚本来替换所需参数的模板处理工具生成配置，通过为同一模板设置不同的值来达到复用的目的。而这种方式面临的问题是模板和参数文件并不在 kubernetes API 资源的规范中，这种方式必定是一种包装了 kubernetes API 的新东西、新语言。虽然这种方式很强大，但是也带来了学习成本和安装工具的成本。不同的团队需要不同的更改，因此几乎所有可以包含在 YAML 文件中的规范都会需要抽象成参数。&lt;/p&gt;

&lt;h2 id=&#34;自定义配置的新选择&#34;&gt;自定义配置的新选择&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;kustomize&lt;/strong&gt; 中工具的声明与规范是由名为 &lt;code&gt;kustomization.yaml&lt;/code&gt; 的文件定义。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;kustomize&lt;/strong&gt; 将会读取声明文件和 Kubernetes API 资源文件，将其组合然后将完整的资源进行标准化的输出。输出的文本可以被其他工具进一步处理，或者直接通过 &lt;strong&gt;kubectl&lt;/strong&gt; 应用于集群。&lt;/p&gt;

&lt;p&gt;例如，如果 &lt;code&gt;kustomization.yaml&lt;/code&gt; 文件包括：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;commonLabels:
  app: hello
resources:
- deployment.yaml
- configMap.yaml
- service.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;确保这三个文件与 &lt;code&gt;kustomization.yaml&lt;/code&gt; 位于同一目录下，然后运行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将创建包含三个资源的 YAML 流，其中 &lt;code&gt;app: hello&lt;/code&gt; 为每个资源共同的标签。&lt;/p&gt;

&lt;p&gt;同样的，你可以使用 &lt;strong&gt;&lt;em&gt;commonAnnotations&lt;/em&gt;&lt;/strong&gt; 字段给所有资源添加注释， &lt;strong&gt;&lt;em&gt;namePrefix&lt;/em&gt;&lt;/strong&gt; 字段为所有的资源添加共同的前缀名。这些琐碎而有常见的定制只是一个开始。&lt;/p&gt;

&lt;p&gt;一个更常见的例子是，你需要为一组相同资源设置不同的参数。例如：开发、演示和生产的参数。&lt;/p&gt;

&lt;p&gt;为此，&lt;strong&gt;Kustomize&lt;/strong&gt; 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。两者都是由 kustomization 文件表示。基础（Base）声明了共享的内容（资源和常见的资源配置），Overlay 则声明了差异。&lt;/p&gt;

&lt;p&gt;这里是一个目录树，用于管理集群应用程序的 &lt;strong&gt;&lt;em&gt;演示&lt;/em&gt;&lt;/strong&gt; 和 &lt;strong&gt;&lt;em&gt;生产&lt;/em&gt;&lt;/strong&gt; 配置参数：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;someapp/
├── base/
│   ├── kustomization.yaml
│   ├── deployment.yaml
│   ├── configMap.yaml
│   └── service.yaml
└── overlays/
    ├── production/
    │   └── kustomization.yaml
    │   ├── replica_count.yaml
    └── staging/
        ├── kustomization.yaml
        └── cpu_count.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;someapp/base/kustomization.yaml&lt;/code&gt; 文件指定了公共资源和常见自定义配置（例如，它们一些相同的标签，名称前缀和注释）。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;someapp/overlays/production/kustomization.yaml&lt;/code&gt; 文件的内容可能是：&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;commonLabels:
  env: production
bases:
- ../../base
patches:
- replica_count.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个 kustomization 指定了一个 &lt;strong&gt;&lt;em&gt;patch&lt;/em&gt;&lt;/strong&gt; 文件 &lt;code&gt;replica_count.yaml&lt;/code&gt; ，其内容可能是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: the-deployment
spec:
  replicas: 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;patch&lt;/em&gt;&lt;/strong&gt; 是部分的资源声明，在这个例子中是 Deployment 的补丁 &lt;code&gt;someapp/base/deployment.yaml&lt;/code&gt; ，仅修改了副本数用以处理生产流量。&lt;/p&gt;

&lt;p&gt;该补丁不仅仅是一个无上下文 {parameter name，value} 元组。其作为部分 deployment spec，可以通过验证，即使与其余配置隔离读取，也具有明确的上下文和用途。&lt;/p&gt;

&lt;p&gt;要为生产环境创建资源，请运行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kustomize build someapp/overlays/production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果将作为一组完整资源打印到标准输出，并准备应用于集群。可以用类似的命令定义演示环境的配置。&lt;/p&gt;

&lt;h2 id=&#34;综上所述&#34;&gt;综上所述&lt;/h2&gt;

&lt;p&gt;使用 &lt;strong&gt;kustomize&lt;/strong&gt; ，您可以仅使用 Kubernetes API 资源文件就可以管理任意数量的 Kubernetes 定制配置。kustomize 的每个产物都是纯 YAML 的，每个都可以进行验证和运行的。&lt;strong&gt;kustomize&lt;/strong&gt; 鼓励通过 fork/modify/rebase 这样的&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/workflows.md&#34; target=&#34;_blank&#34;&gt;工作流&lt;/a&gt;来管理海量的应用描述文件。&lt;/p&gt;

&lt;p&gt;尝试&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/tree/master/examples/helloWorld&#34; target=&#34;_blank&#34;&gt;hello world&lt;/a&gt;示例，开始使用 &lt;strong&gt;kustomize&lt;/strong&gt; 吧！有关的反馈与讨论，可以通过加入&lt;a href=&#34;https://groups.google.com/forum/#!forum/kustomize&#34; target=&#34;_blank&#34;&gt;邮件列表&lt;/a&gt;或提 &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/issues/new&#34; target=&#34;_blank&#34;&gt;issue&lt;/a&gt;，欢迎提交PR。&lt;/p&gt;

&lt;h2 id=&#34;译者按&#34;&gt;译者按&lt;/h2&gt;

&lt;p&gt;随着 kubernetes 1.14 的发布，kustomize 被集成到 &lt;code&gt;kubectl&lt;/code&gt; 中，用户可以利用 &lt;code&gt;kubectl apply -k dir/&lt;/code&gt; 将指定目录的 &lt;code&gt;kustomization.yaml&lt;/code&gt; 提交到集群中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;原文链接&lt;/strong&gt; &lt;a href=&#34;https://kubernetes.io/blog/2018/05/29/introducing-kustomize-template-free-configuration-customization-for-kubernetes/&#34; target=&#34;_blank&#34;&gt;https://kubernetes.io/blog/2018/05/29/introducing-kustomize-template-free-configuration-customization-for-kubernetes/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Kustomize 帮你管理 kubernetes 应用（一）：什么是 Kustomize ？</title>
      <link>https://guoxudong.io/en/post/kustomize-1/</link>
      <pubDate>Mon, 15 Apr 2019 13:32:59 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/kustomize-1/</guid>
      <description>

&lt;h2 id=&#34;初识-kustomize&#34;&gt;初识 Kustomize&lt;/h2&gt;

&lt;p&gt;第一次听说 Kustomize 其实是在 kubernetes 1.14 发布时候，它被集成到 &lt;code&gt;kubectl&lt;/code&gt; 中，成为了一个子命令，但也只是扫了一眼，并没有深究。真正让我注意到它，并主动开始了解其功能和使用方法的，是张磊大神在云栖社区发表的一篇文章&lt;a href=&#34;https://yq.aliyun.com/articles/697883&#34; target=&#34;_blank&#34;&gt;《从Kubernetes 1.14 发布，看技术社区演进方向》&lt;/a&gt;，他在文中是这么说的：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Kustomize 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件，而不是像 Helm 那样只提供应用描述文件模板，然后通过字符替换（Templating）的方式来进行定制化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这不正我在苦苦寻找的东西嘛！自从公司确定了应用容器化的方案，至今已有半年多了，这期间我们的服务一个接一个的实现了容器化，部署到了 kubernetes 集群中。kubernetes 集群也有原先了1个测试集群，几个节点，发展到了如今的多个集群，几十个节点。而在推进容器化的过程中，每个服务都对对应多个应用描述文件（ YAML 文件），而根据环境的不同，又配置了多套的应用描述文件。随着服务越部越多，应用描述文件更是呈爆炸式的增长。&lt;/p&gt;

&lt;p&gt;感谢 devops 文化，它是我不需要为每个应用去写 YAML 文件，各个应用的开发组承担了这一工作，我只需要为他们提供基础模板即可。但应用上线后出现的 OOM 、服务无法拉起等 YAML 文件配置有误导致的问题接踵而至，使得我必须要深入各个服务，为他们配置符合他们配置。虽然也使用了 &lt;code&gt;helm&lt;/code&gt; ，但是其只提供应用描述文件模板，在不同环境拉起一整套服务会节省很多时间，而像我们这种在指定环境快速迭代的服务，并不会减少很多时间。针对这种情况，我已经计划要自己开发一套更符合我们工作这种场景的应用管理服务，集成在我们自己的 devops 平台中。&lt;/p&gt;

&lt;p&gt;这时 Kustomize 出现了，我明锐的感觉到 Kustomize 可能就是解决我现阶段问题的一剂良药。&lt;/p&gt;

&lt;h2 id=&#34;什么是-kustomize&#34;&gt;什么是 Kustomize ？&lt;/h2&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;kubernetes-native-configuration-management&#34;&gt;Kubernetes native configuration management&lt;/h4&gt;

&lt;p&gt;Kustomize introduces a template-free way to customize application configuration that simplifies the use of off-the-shelf applications. Now, built into &lt;code&gt;kubectl&lt;/code&gt; as &lt;code&gt;apply -k&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kustomize&lt;/code&gt;  允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。而其他用户可以完全不受影响的使用任何一个 Base YAML 或者任何一层生成出来的 YAML 。这使得每一个用户都可以通过类似fork/modify/rebase 这样 Git 风格的流程来管理海量的应用描述文件。这种 PATCH 的思想跟 Docker 镜像是非常相似的，它可以规避“字符替换”对应用描述文件的入侵，也不需要用户学习额外的 DSL 语法（比如 Lua）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;而其成为 &lt;code&gt;kubectl&lt;/code&gt; 子命令则代表这 &lt;code&gt;kubectl&lt;/code&gt; 本身的插件机制的成熟，未来可能有更多的工具命令集成到 &lt;code&gt;kubectl&lt;/code&gt; 中。拿张磊大神的这张图不难看出，在 kubernetes 原生应用管理系统中，应用描述文件在整个应用管理体系中占据核心位置，通过应用描述文件可以组合和编排多种 kubernetes API 资源，kubernetes 通过控制器来保证集群中的资源与应用状态与描述文件完全一致。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://wx4.sinaimg.cn/large/ad5fbf65gy1g23cqlrodkj21bq0r8znk.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Kustomize 不像 Helm 那样需要一整套独立的体系来完成管理应用，而是完全采用 kubernetes 的设计理念来完成管理应用的目的。同时使用起来也更加的得心应手。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kustomize.io/&#34; target=&#34;_blank&#34;&gt;Kustomize - kustomize.io&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://yq.aliyun.com/articles/697883&#34; target=&#34;_blank&#34;&gt;从Kubernetes 1.14 发布，看技术社区演进方向 - yq.aliyun.com&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>自动合并Kubeconfig，实现多k8s集群切换</title>
      <link>https://guoxudong.io/en/post/merge-kubeconfig/</link>
      <pubDate>Sun, 17 Mar 2019 10:45:02 +0800</pubDate>
      
      <guid>https://guoxudong.io/en/post/merge-kubeconfig/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;随着微服务和容器化的深入人心，以及kubernetes已经成为容器编排领域的事实标准，越来越多的公司将自己的服务迁移到kubernetes集群中。而随着kubernetes集群的增加，集群管理的问题就凸显出来，不同的环境存在不同的集群，不同的业务线不同的集群，甚至有些开发人员都有自己的集群。诚然，如果集群是使用公有云如阿里云或华为云的容器服务，可以登录其控制台进行集群管理；或者使用rancher这用的多集群管理工具进行统一的管理。但是在想操作&lt;code&gt;istio&lt;/code&gt;特有的容器资源，或者想使用&lt;code&gt;istioctl&lt;/code&gt;的时候，或者像我一样就是想使用&lt;code&gt;kubectl&lt;/code&gt;命令的同学，这个时候多集群的切换就显的十分重要了。&lt;/p&gt;

&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-kubectl```命令行工具通过```kubeconfig```文件的配置来选择集群以及集群的API&#34;&gt;
## 原理
使用```kubeconfig```文件，您可以组织您的群集，用户和名称空间。 还可以定义上下文以快速轻松地在群集和名称空间之间切换。

### 上下文(Context) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kubeconfig```文件中的上下文元素用于以方便的名称对访问参数进行分组。 每个上下文有三个参数：集群，命名空间和用户。 默认情况下，kubectl命令行工具使用当前上下文中的参数与集群进行通信。可以使用下面的命令设置上下文：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;kubectl config use-context
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置内容&#34;&gt;配置内容&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;kubectl config view
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;如果设置了&lt;code&gt;--kubeconfig&lt;/code&gt;标志，则只使用指定的文件。该标志只允许有一个实例。&lt;/li&gt;
&lt;li&gt;如果环境变量&lt;code&gt;KUBECONFIG&lt;/code&gt;存在，那么就使用该环境变量&lt;code&gt;KUBECONFIG&lt;/code&gt;里面的值，如果不存在该环境变量&lt;code&gt;KUBECONFIG&lt;/code&gt;，那么默认就是使用&lt;code&gt;$HOME/.kube/config&lt;/code&gt;文件。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;kubeconfig-内容&#34;&gt;&lt;code&gt;kubeconfig&lt;/code&gt;内容&lt;/h3&gt;

&lt;p&gt;从下面kubeconfig文件的配置来看集群、用户、上下文、当前上下文的关系就比较明显了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Config
preferences: {}

clusters:
- cluster:
name: {cluster-name}

users:
- name: {user-name}

contexts:
- context:
    cluster: {cluster-name}
    user: {user-name}
name: {context-name}

current-context: {context-name}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;为何要自动合并&#34;&gt;为何要自动合并&lt;/h2&gt;

&lt;p&gt;在日常的工作中，如果我们需要操作多个集群，会得到多个kubeconfig配置文件。一般的kubeconfig文件都是yaml格式的，但是也有少部分的集群kubeconfig时已json文件的形式给出的（比如华为云的=。=），比如我们公司再阿里云、华为云和自建环境上均存在kubernetes集群，平时操作要在多集群之间切换，这也就催生了我写这个工具（其实就是一个脚本）的动机。&lt;/p&gt;

&lt;h2 id=&#34;自动合并生成kubeconfig&#34;&gt;自动合并生成kubeconfig&lt;/h2&gt;

&lt;p&gt;众所周知，yaml是一种直观的能够被电脑识别的数据序列化格式，是一个可读性高并且容易被人类阅读的语言和json相比（没有格式化之前）可读性更强。而我这个工具并不是很关心kubeconfig的格式，只要将想要合并的kubeconfig放入指定文件即可。&lt;/p&gt;

&lt;p&gt;GitHub：&lt;a href=&#34;https://github.com/sunny0826/mergeKubeConfig&#34; target=&#34;_blank&#34;&gt;https://github.com/sunny0826/mergeKubeConfig&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;适用环境&#34;&gt;适用环境&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;需要在终端使用命令行管理多集群&lt;/li&gt;
&lt;li&gt;kubernetes集群中安装了istio，需要使用&lt;code&gt;istioctl&lt;/code&gt;命令，但是集群节点并没有安装&lt;code&gt;istioctl&lt;/code&gt;，需要在本地终端操作&lt;/li&gt;
&lt;li&gt;不愿频繁编辑.kube目录中的config文件的同学&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;准备工作&#34;&gt;准备工作&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Python环境：2.7或者3均可&lt;/li&gt;
&lt;li&gt;需要依赖包：&lt;code&gt;PyYAML&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;开始使用&#34;&gt;开始使用&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装依赖：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install PyYAML
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;运行脚本&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;默认运行方式，kubeconfig文件放入&lt;code&gt;configfile&lt;/code&gt;文件,注意删掉作为示例的两个文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python merge.py
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;自定义kubeconfig文件目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python merge.py -d {custom-dir}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;运行后操作&#34;&gt;运行后操作&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;将生成的config文件放入.kube目录中&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp config ~/.kube
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;查看所有的可使用的kubernetes集群角色&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl config get-contexts
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;更多关于kubernetes配置文件操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl config --help
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;切换kubernetes配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl config use-context {your-contexts}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;

&lt;p&gt;在使用kubernetes初期，在多集群之间我一直是频繁的切换&lt;code&gt;.kube/config&lt;/code&gt;文件来达到切换操作集群的目的。这也导致了我的&lt;code&gt;.kube&lt;/code&gt;目录中存在这多个类似于&lt;code&gt;al_test_config.bak&lt;/code&gt;、&lt;code&gt;al_prod_config.bak&lt;/code&gt;、&lt;code&gt;hw_test_config.bak&lt;/code&gt;的文件，本地环境已经自建环境，在集群切换的时候十分头疼。而后来使用&lt;code&gt;--kubeconfig&lt;/code&gt;来进行切换集群，虽然比之前的方法要方便很多，但是并不十分优雅。这个简单的小工具一举解决了我的文件，对于我这个&lt;code&gt;kubectl&lt;/code&gt;重度依赖者来说十分重要。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
