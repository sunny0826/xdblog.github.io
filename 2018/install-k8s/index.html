<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="XuDong.Guo">
  <meta name="description" content="码到成功">
  
  
  <link rel="prev" href="https://blog.maoxianplay.com/2018/install-docker/" />
  <link rel="next" href="https://blog.maoxianplay.com/2018/con-ind/" />
  <link rel="canonical" href="https://blog.maoxianplay.com/2018/install-k8s/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="stylesheet" href="/css/share.min.css" />
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           centos7.2 安装k8s v1.11.0 | MaoXian Play
       
  </title>
  <meta name="title" content="centos7.2 安装k8s v1.11.0 | MaoXian Play">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://blog.maoxianplay.com/"
    },
    "articleSection" : "posts",
    "name" : "centos7.2 安装k8s v1.11.0",
    "headline" : "centos7.2 安装k8s v1.11.0",
    "description" : "前言  最近由于公司业务发展到了瓶颈，原有的技术架构已经逐渐无法满足业务开发和测试的需求，出现了应用测试环境搭建复杂，有许多套（真的很多很多）应用环境，应用在持续集成/持续交付也遇到了很大的困难，经过讨论研究决定对应用和微服务进行容器化，这就是我首次直面docker和k8s的契机（好吧，我是菜鸟）
 Kubernetes 介绍 Kubernetes 是 Google 团队发起的开源项目，它的目标是管理跨多个主机的容器，提供基本的部署，维护以及运用伸缩，主要实现语言为 Go 语言。 Kubernetes的特点：
 易学：轻量级，简单，容易理解 便携：支持公有云，私有云，混合云，以及多种云平台 可拓展：模块化，可插拔，支持钩子，可任意组合 自修复：自动重调度，自动重启，自动复制  准备工作 注：以下操作都是在root权限下执行的
 安装docker-ce，这里使用docker-ce-17.09.0.c版本，安装方法见之前的教程 安装Kubeadm
#安装 Kubeadm 首先我们要配置好阿里云的国内源，执行如下命令： cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 EOF #之后，执行以下命令来重建yum缓存： yum -y install epel-releaseyum clean all yum makecache  接下来需要安装指定版本的Kubeadm（这里要安装指定版本，因为后续依赖的镜像由于有墙无法拉取，这里我们只有指定版本的镜像），注意：这里是安装指定版本的Kubeadm，k8s的版本更新之快完全超出你的想象！
yum -y install kubelet-1.11.0-0 yum -y install kubeadm-1.11.0-0 yum -y install kubectl-1.11.0-0 yum -y install kubernetes-cni #执行命令启动Kubeadm服务： systemctl enable kubelet &amp;&amp; systemctl start kubelet  配置 Kubeadm 所用到的镜像 这里是重中之重，因为在国内的原因，无法访问到 Google 的镜像库，所以我们需要执行以下脚本来从 Docker Hub 仓库中获取相同的镜像，并且更改 TAG 让其变成与 Google 拉去镜像一致。",
    "inLanguage" : "en-us",
    "author" : "XuDong.Guo",
    "creator" : "XuDong.Guo",
    "publisher": "XuDong.Guo",
    "accountablePerson" : "XuDong.Guo",
    "copyrightHolder" : "XuDong.Guo",
    "copyrightYear" : "2018",
    "datePublished": "2018-08-14 20:07:03 &#43;0800 CST",
    "dateModified" : "2018-08-14 20:07:03 &#43;0800 CST",
    "url" : "https://blog.maoxianplay.com/2018/install-k8s/",
    "wordCount" : "1395",
    "keywords" : [ "容器","kubernetes", "MaoXian Play"]
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://blog.maoxianplay.com/">MaoXian Play</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/" title="">home</a>
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://blog.maoxianplay.com/">MaoXian Play</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/" title="">home</a>
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">centos7.2 安装k8s v1.11.0</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://blog.maoxianplay.com/" rel="author">XuDong.Guo</a> with ♥ 
                <span class="post-time">
                on <time datetime=2018-08-14 itemprop="datePublished">August 14, 2018</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="https://blog.maoxianplay.com/categories/%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85/"> 部署安装 </a>
                        
                </span>
                
                <h5 id="wc">1400 Words|Read in about 7 Min|本文总阅读量<span id="busuanzi_value_page_pv"></span>次</h5>
                <h5 id="tags">Tags: 
                    
                    <a href="https://blog.maoxianplay.com/tags/%E5%AE%B9%E5%99%A8/">容器</a> &nbsp;
                    
                    <a href="https://blog.maoxianplay.com/tags/kubernetes/">kubernetes</a> &nbsp;
                </h5>
        </div>
    </header>
    <div class="post-content">
        
        
        

        
        
          
          
          

          
          
          

          

<h1 id="前言">前言</h1>

<blockquote>
<p>最近由于公司业务发展到了瓶颈，原有的技术架构已经逐渐无法满足业务开发和测试的需求，出现了应用测试环境搭建复杂，有许多套（真的很多很多）应用环境，应用在持续集成/持续交付也遇到了很大的困难，经过讨论研究决定对应用和微服务进行容器化，这就是我首次直面docker和k8s的契机（好吧，我是菜鸟）</p>
</blockquote>

<h1 id="kubernetes-介绍">Kubernetes 介绍</h1>

<p>Kubernetes 是 Google 团队发起的开源项目，它的目标是管理跨多个主机的容器，提供基本的部署，维护以及运用伸缩，主要实现语言为
Go 语言。
Kubernetes的特点：</p>

<ul>
<li>易学：轻量级，简单，容易理解</li>
<li>便携：支持公有云，私有云，混合云，以及多种云平台</li>
<li>可拓展：模块化，可插拔，支持钩子，可任意组合</li>
<li>自修复：自动重调度，自动重启，自动复制</li>
</ul>

<h1 id="准备工作">准备工作</h1>

<p><strong>注：以下操作都是在root权限下执行的</strong></p>

<ol>
<li>安装docker-ce，这里使用docker-ce-17.09.0.c版本，安装方法见<a href="/2018/install-docker">之前的教程</a></li>

<li><p>安装Kubeadm</p>

<pre><code>#安装 Kubeadm 首先我们要配置好阿里云的国内源，执行如下命令：
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
EOF

#之后，执行以下命令来重建yum缓存：
yum -y install epel-releaseyum
clean all
yum makecache
</code></pre>

<p>接下来需要安装指定版本的Kubeadm（这里要安装指定版本，因为后续依赖的镜像由于有墙无法拉取，这里我们只有指定版本的镜像），注意：<strong>这里是安装指定版本的Kubeadm，k8s的版本更新之快完全超出你的想象！</strong></p>

<pre><code>yum -y install kubelet-1.11.0-0
yum -y install kubeadm-1.11.0-0
yum -y install kubectl-1.11.0-0
yum -y install kubernetes-cni

#执行命令启动Kubeadm服务：
systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre></li>

<li><p>配置 Kubeadm 所用到的镜像
这里是重中之重，因为在国内的原因，无法访问到 Google 的镜像库，所以我们需要执行以下脚本来从 Docker Hub 仓库中获取相同的镜像，并且更改 TAG 让其变成与 Google 拉去镜像一致。</p>

<p><strong>新建一个 Shell 脚本，填入以下代码之后保存</strong></p>

<pre><code>#docker.sh
#!/bin/bash
images=(kube-proxy-amd64:v1.11.0 kube-scheduler-amd64:v1.11.0 kube-controller-manager-amd64:v1.11.0 kube-apiserver-amd64:v1.11.0 etcd-amd64:3.2.18 coredns:1.1.3 pause-amd64:3.1 kubernetes-dashboard-amd64:v1.8.3 k8s-dns-sidecar-amd64:1.14.9 k8s-dns-kube-dns-amd64:1.14.9 k8s-dns-dnsmasq-nanny-amd64:1.14.9 )
for imageName in ${images[@]} ; do
docker pull keveon/$imageName
docker tag keveon/$imageName k8s.gcr.io/$imageName
docker rmi keveon/$imageName
done
# 个人新加的一句，V 1.11.0 必加
docker tag da86e6ba6ca1 k8s.gcr.io/pause:3.1
</code></pre>

<p><strong>保存后使用chmod命令赋予脚本执行权限</strong></p>

<pre><code>chmod -R 777 ./docker.sh
</code></pre>

<p><strong>执行脚本拉取镜像</strong></p>

<pre><code>sh docker.sh
#这里就开始了漫长的拉取镜像之路
</code></pre>

<p><strong>关闭掉swap</strong></p>

<pre><code>sudo swapoff -a
#要永久禁掉swap分区，打开如下文件注释掉swap那一行
# sudo vi /etc/stab
</code></pre>

<p><strong>关闭SELinux的</strong></p>

<pre><code># 临时禁用selinux
# 永久关闭 修改/etc/sysconfig/selinux文件设置
sed -i 's/SELINUX=permissive/SELINUX=disabled/' /etc/sysconfig/selinux
# 这里按回车，下面是第二条命令
setenforce 0
</code></pre>

<p><strong>关闭防火墙</strong></p>

<pre><code>systemctl disable firewalld.service &amp;&amp; systemctl stop firewalld.service
</code></pre>

<p><strong>配置转发参数</strong></p>

<pre><code># 配置转发相关参数，否则可能会出错
cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
vm.swappiness=0
EOF
# 这里按回车，下面是第二条命令
sysctl --system
</code></pre>

<p><strong>这里就完成了k8s集群搭建的准备工作，集群搭建的话以上操作结束后将操作完的系统制作成系统镜像，方便集群搭建</strong></p></li>
</ol>

<h1 id="正式安装">正式安装</h1>

<p><strong>以下的操作都只在主节点上进行：</strong></p>

<p><strong>初始化镜像</strong></p>

<pre><code>kubeadm init --kubernetes-version=v1.11.0 --pod-network-cidr=10.10.0.0/16  #这里填写集群所在网段
</code></pre>

<p><strong>之后的输出会是这样：</strong></p>

<pre><code>I0712 10:46:30.938979   13461 feature_gate.go:230] feature gates: &amp;{map[]}
[init] using Kubernetes version: v1.11.0
[preflight] running pre-flight checks
I0712 10:46:30.961005   13461 kernel_validator.go:81] Validating kernel version
I0712 10:46:30.961061   13461 kernel_validator.go:96] Validating kernel config
    [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.03.1-ce. Max validated version: 17.03
    [WARNING Hostname]: hostname &quot;g2-apigateway&quot; could not be reached
    [WARNING Hostname]: hostname &quot;g2-apigateway&quot; lookup g2-apigateway on 100.100.2.138:53: no such host
[preflight/images] Pulling images required for setting up a Kubernetes cluster
[preflight/images] This might take a minute or two, depending on the speed of your internet connection
[preflight/images] You can also perform this action in beforehand using 'kubeadm config images pull'
[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[preflight] Activating the kubelet service
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [g2-apigateway kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.8.62]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Generated etcd/ca certificate and key.
[certificates] Generated etcd/server certificate and key.
[certificates] etcd/server serving cert is signed for DNS names [g2-apigateway localhost] and IPs [127.0.0.1 ::1]
[certificates] Generated etcd/peer certificate and key.
[certificates] etcd/peer serving cert is signed for DNS names [g2-apigateway localhost] and IPs [172.16.8.62 127.0.0.1 ::1]
[certificates] Generated etcd/healthcheck-client certificate and key.
[certificates] Generated apiserver-etcd-client certificate and key.
[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;
[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;
[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;
[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;
[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;
[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;
[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;
[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;
[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;
[init] this might take a minute or longer if the control plane images have to be pulled
[apiclient] All control plane components are healthy after 41.001672 seconds
[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace
[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster
[markmaster] Marking the node g2-apigateway as master by adding the label &quot;node-role.kubernetes.io/master=''&quot;
[markmaster] Marking the node g2-apigateway as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;g2-apigateway&quot; as an annotation
[bootstraptoken] using token: o337m9.ceq32wg9g2gro7gx
[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

kubeadm join 10.10.207.253:6443 --token t69z6h.lr2etdbg9mfx5r15 --discovery-token-ca-cert-hash sha256:90e3a748c0eb4cb7058f3d0ee8870ee5d746214ab0589b5e841fd5d68fec8f00
</code></pre>

<p><strong>这里注意最后一行：</strong></p>

<pre><code>kubeadm join 10.10.207.253:6443 --token t69z6h.lr2etdbg9mfx5r15 --discovery-token-ca-cert-hash sha256:90e3a748c0eb4cb7058f3d0ee8870ee5d746214ab0589b5e841fd5d68fec8f00
</code></pre>

<p>证明集群主节点安装成功，这里要记得保存这条命令，以便之后各个节点加入集群</p>

<p><strong>配置kubetl认证信息</strong></p>

<pre><code>export KUBECONFIG=/etc/kubernetes/admin.conf
# 如果你想持久化的话，直接执行以下命令【推荐】
echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile
</code></pre>

<p><strong>安装flanel网络</strong></p>

<pre><code>mkdir -p /etc/cni/net.d/

cat &lt;&lt;EOF&gt; /etc/cni/net.d/10-flannel.conf
{
&quot;name&quot;: &quot;cbr0&quot;,
&quot;type&quot;: &quot;flannel&quot;,
&quot;delegate&quot;: {
&quot;isDefaultGateway&quot;: true
}
}
EOF

mkdir /usr/share/oci-umount/oci-umount.d -p

mkdir /run/flannel/

cat &lt;&lt;EOF&gt; /run/flannel/subnet.env
FLANNEL_NETWORK=10.244.0.0/16
FLANNEL_SUBNET=10.244.1.0/24
FLANNEL_MTU=1450
FLANNEL_IPMASQ=true
EOF
</code></pre>

<p><strong>最后需要新建一个flannel.yml文件：</strong></p>

<pre><code>---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
name: flannel
rules:
- apiGroups:
    - &quot;&quot;
    resources:
    - pods
    verbs:
    - get
- apiGroups:
    - &quot;&quot;
    resources:
    - nodes
    verbs:
    - list
    - watch
- apiGroups:
    - &quot;&quot;
    resources:
    - nodes/status
    verbs:
    - patch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
name: flannel
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: flannel
subjects:
- kind: ServiceAccount
name: flannel
namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
name: flannel
namespace: kube-system
---
kind: ConfigMap
apiVersion: v1
metadata:
name: kube-flannel-cfg
namespace: kube-system
labels:
    tier: node
    app: flannel
data:
cni-conf.json: |
    {
    &quot;name&quot;: &quot;cbr0&quot;,
    &quot;type&quot;: &quot;flannel&quot;,
    &quot;delegate&quot;: {
        &quot;isDefaultGateway&quot;: true
    }
    }
net-conf.json: |
    {
    &quot;Network&quot;: &quot;10.10.0.0/16&quot;,    #这里换成集群所在的网段
    &quot;Backend&quot;: {
        &quot;Type&quot;: &quot;vxlan&quot;
    }
    }
---
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
name: kube-flannel-ds
namespace: kube-system
labels:
    tier: node
    app: flannel
spec:
template:
    metadata:
    labels:
        tier: node
        app: flannel
    spec:
    hostNetwork: true
    nodeSelector:
        beta.kubernetes.io/arch: amd64
    tolerations:
    - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
    serviceAccountName: flannel
    initContainers:
    - name: install-cni
        image: quay.io/coreos/flannel:v0.9.1-amd64
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conf
        volumeMounts:
        - name: cni
        mountPath: /etc/cni/net.d
        - name: flannel-cfg
        mountPath: /etc/kube-flannel/
    containers:
    - name: kube-flannel
        image: quay.io/coreos/flannel:v0.9.1-amd64
        command: [ &quot;/opt/bin/flanneld&quot;, &quot;--ip-masq&quot;, &quot;--kube-subnet-mgr&quot; ]
        securityContext:
        privileged: true
        env:
        - name: POD_NAME
        valueFrom:
            fieldRef:
            fieldPath: metadata.name
        - name: POD_NAMESPACE
        valueFrom:
            fieldRef:
            fieldPath: metadata.namespace
        volumeMounts:
        - name: run
        mountPath: /run
        - name: flannel-cfg
        mountPath: /etc/kube-flannel/
    volumes:
        - name: run
        hostPath:
            path: /run
        - name: cni
        hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
        configMap:
            name: kube-flannel-cfg
</code></pre>

<p><strong>执行：</strong></p>

<pre><code>kubectl create -f ./flannel.yml
</code></pre>

<p>默认情况下，master节点不参与工作负载，但如果希望安装出一个all-in-one的k8s环境，则可以执行以下命令：</p>

<p><strong>让master节点成为一个node节点：</strong></p>

<pre><code>kubectl taint nodes --all node-role.kubernetes.io/master-
</code></pre>

<p><strong>查看节点信息：</strong></p>

<pre><code>kubectl get nodes
</code></pre>

<p><strong>会看到如下的输出：</strong></p>

<pre><code>NAME            STATUS     ROLES     AGE       VERSION
k8s-master      Ready      master    18h       v1.11.0
</code></pre>

<p><strong>以下是节点配置</strong></p>

<p>在配置好主节点之后，就可以配置集群的其他节点了，这里建议直接安装之前做好准备工作的系统镜像
进入节点机器之后，直接执行之前保存好的命令</p>

<pre><code>kubeadm join 10.10.207.253:6443 --token t69z6h.lr2etdbg9mfx5r15 --discovery-token-ca-cert-hash sha256:90e3a748c0eb4cb7058f3d0ee8870ee5d746214ab0589b5e841fd5d68fec8f00
</code></pre>

<p>执行完后会看到：</p>

<pre><code>[preflight] running pre-flight checks
        [WARNING RequiredIPVSKernelModulesAvailable]: the IPVS proxier will not be used, because the following required kernel modules are not loaded: [ip_vs_wrr ip_vs_sh ip_vs ip_vs_rr] or no builtin kernel ipvs support: map[ip_vs_rr:{} ip_vs_wrr:{} ip_vs_sh:{} nf_conntrack_ipv4:{} ip_vs:{}]
you can solve this problem with following methods:
1. Run 'modprobe -- ' to load missing kernel modules;
2. Provide the missing builtin kernel ipvs support

I0725 09:59:27.929247   10196 kernel_validator.go:81] Validating kernel version
I0725 09:59:27.929356   10196 kernel_validator.go:96] Validating kernel config
[discovery] Trying to connect to API Server &quot;10.10.207.253:6443&quot;
[discovery] Created cluster-info discovery client, requesting info from &quot;https://10.10.207.253:6443&quot;
[discovery] Requesting info from &quot;https://10.10.207.253:6443&quot; again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &quot;10.10.207.253:6443&quot;
[discovery] Successfully established connection with API Server &quot;10.10.207.253:6443&quot;
[kubelet] Downloading configuration for the kubelet from the &quot;kubelet-config-1.11&quot; ConfigMap in the kube-system namespace
[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[preflight] Activating the kubelet service
[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...
[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;k8s-node1&quot; as an annotation

This node has joined the cluster:
* Certificate signing request was sent to master and a response
was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the master to see this node join the cluster.
</code></pre>

<p><strong>这里就表示执行完毕了，可以去主节点执行命令：</strong></p>

<pre><code>kubectl get nodes
</code></pre>

<p><strong>可以看到节点已加入集群：</strong></p>

<pre><code>NAME        STATUS    ROLES     AGE       VERSION
k8s-master  Ready     master    20h       v1.11.0
k8s-node1   Ready     &lt;none&gt;    20h       v1.11.0
k8s-node2   Ready     &lt;none&gt;    20h       v1.11.0
</code></pre>

<p>这期间可能需要等待一段时间，状态才会全部变为ready</p>

<h1 id="kubernetes-dashboard安装">kubernetes-dashboard安装</h1>

<p>详见：<a href="/2018/dashboard-k8s">kubernetes安装dashboard</a></p>

<h1 id="采坑指南">采坑指南</h1>

<p>有时会出现master节点一直处于notready的状态，这里可能是没有启动flannel，只需要按照上面的教程配置好flannel，然后执行：</p>

<pre><code>kubectl create -f ./flannel.yml
</code></pre>

    </div>
    <div id="container"></div>
    <link rel="stylesheet" href="https://billts.site/extra_css/gitment.css">
    <script src="https://billts.site/js/gitment.js"></script>
    <script>
    var gitment = new Gitment({
      owner: 'sunny0826',              
      repo: 'xdblog.github.io',                 
      oauth: {
        client_id: '3ef9f9cd4c4ed7dc26c0',          
        client_secret: '28bc547ce26ef11909e05016997a0a9a6cf17ebb',  
      },
    })
    gitment.render('container')
    </script>
    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>XuDong.Guo </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://blog.maoxianplay.com/2018/install-k8s/>https://blog.maoxianplay.com/2018/install-k8s/</span>
            </p>
            
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="https://blog.maoxianplay.com/tags/%E5%AE%B9%E5%99%A8/">
                    #容器</a></span>
            
            <span class="tag"><a href="https://blog.maoxianplay.com/tags/kubernetes/">
                    #kubernetes</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://blog.maoxianplay.com/">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://blog.maoxianplay.com/2018/install-docker/" class="prev" rel="prev" title="centos7安装指定版本的docker"><i class="iconfont icon-left"></i>&nbsp;centos7安装指定版本的docker</a>
         
        
        <a href="https://blog.maoxianplay.com/2018/con-ind/" class="next" rel="next" title="容器技术概述">容器技术概述&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
    <div class="social-share" data-initialized="true" data-wechat-qrcode-title="不扫别后悔">
    <center>
    <font style="font-size:18px;color:darkcyan;">分享到：</font>
    <a href="#" class="social-share-icon icon-weibo"></a>
    <a href="#" class="social-share-icon icon-wechat"></a>
    <a href="#" class="social-share-icon icon-twitter"></a>
    <a href="#" class="social-share-icon icon-linkedin"></a>
    <a href="#" class="social-share-icon icon-facebook"></a>
    <a href="#" class="social-share-icon icon-qq"></a>
    <a href="#" class="social-share-icon icon-qzone"></a>
    </center>
</div>


<script src="https://hugo-picture.oss-cn-beijing.aliyuncs.com/social-share.min.js"></script>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2018 - 2019</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="https://blog.maoxianplay.com/">XuDong.Guo</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
          <span id="busuanzi_container_site_pv">
            本站访问量：<span id="busuanzi_value_site_pv"></span>次
          </span>
          &nbsp;
          <span id="busuanzi_container_site_uv">
            您是本站第 <span id="busuanzi_value_site_uv"></span> 位访问者
          </span>
    </div>
</footer>












    
    
    <script src="/js/vendor_no_gallery.min.js" async=""></script>
    
  






<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    $(document).ready(function() {
        var int = setInterval(fixCount, 100);
        var busuanziSiteOffset =  100000 
        function fixCount() {
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                clearInterval(int);
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + busuanziSiteOffset);
            }
        }
    });
</script>

     </div>
  </body>
</html>
