<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on MaoXian Play</title>
    <link>https://blog.maoxianplay.com/posts/</link>
    <description>Recent content in Posts on MaoXian Play</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Mar 2019 19:18:13 +0800</lastBuildDate>
    
	<atom:link href="https://blog.maoxianplay.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Pod质量服务类别(QoS)</title>
      <link>https://blog.maoxianplay.com/2019/k8s-qos/</link>
      <pubDate>Mon, 04 Mar 2019 19:18:13 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2019/k8s-qos/</guid>
      <description>根据Pod对象的requests和limits属性，kubernetes将Pod对象归类到BestEffort、Burstable和Guaranteed三个服务质量（Quality of Service，QoS）类别
  Guaranteed  cpu:requests=limits memory:requests=limits 这类Pod具有最高优先级  Burstable  至少一个容器设置了cpu或内存资源的requests 这类Pod具有中等优先级  BestEffort  未有任何一个容器设置requests或limits属性 这类Pod具有最低优先级   同级别优先级的Pod资源在OOM时，与自身的requests属性相比，其内存占用比例最大的Pod对象将被首先杀死。如上图同属Burstable类别的Pod A将先于Pod B被杀死，虽然其内存用量小，但与自身的requests值相比，它的占用比例95%要大于Pod B的80%。</description>
    </item>
    
    <item>
      <title>理解十二要素应用(12-Factor)</title>
      <link>https://blog.maoxianplay.com/2019/12-factor/</link>
      <pubDate>Thu, 14 Feb 2019 14:07:06 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2019/12-factor/</guid>
      <description> 背景  为了更好的拥抱云原生架构，同时提高软件交付质量，开发人员必须改变他们的编码方式，并未开发者和应用程序所运行的基础架构之间创造一个新的协议，十二要素应用宣言应运而生。
 构建云原生应用程序时  使用详实的设计，尽量自动化已降低时间成本和资源花费 在不同环境（测试&amp;amp;生产）和不同平台（Linux&amp;amp;Windows）中应用程序的可移植性 使用适于云平台的应用程序，并了解资源分配和管理 使用一致的环境，减少持续交付/部署中的错误，从而最大限度地发挥软件的敏捷性 通过最少的监督和设计灾难恢复框架来扩展应用程序，实现高可用性  十二要素应用宣言  基础代码：每份部署代码都使用版本控制追踪，并在不同的平台中部署多个实例 依赖管理：应用程序应该显式声明依赖关系，并使用工具在单独管理依赖，例如Bundler、pip和Maven 定义配置：不同环境中的配置（例如环境变量）可能会不同，例如开发环境、预发布环境和生产环境应该在操作系统级定义 后端服务：所有资源都要被当做应用程序自身的一部分来对待。例如数据库、消息队列这样的后端服务应该被当做附加资源来看待，在所有的环境中以相同的方式被消费 构建、发布、运行：包括构建组件、绑定配置，根据绑定的组件和配置文件启动一个或多个实例 进程无状态：以一个或多个无状态进程运行应用（例如master和worker），进程实例之间不共享任何内容 服务端口绑定：应用程序应当自包含，如果有任何需要对外暴露的服务，应当使用端口绑定的形式来完成（首选HTTP） 扩容无状态应用：该架构应该强调基础平台中的无状态进程管理，而不是实现更复杂的应用程序 进程状态管理：进程应该可以迅速地增加，并在一小段时间后正常关闭。在这些方面可实现快速可拓展性、部署更改和灾难恢复 持续发布和部署到生产：保持环境一致，不论是预发布环境还是生产环境。这样可以保证在跨越不同的环境时获取相似的结果，有利于向生产环境持续交付 把日志当事件流：不论是平台级的日志，还是应用级的日志，都十分重要，因为日志可以帮助你了解应用程序背后都做了什么 后台管理任务呗当作一次性进程运行：在云原生的方法中，作为应用程序发布一部分的管理任务（例如数据库迁移）应该作为一次性进程运行，而不是作为常规应用程序长时间运行  </description>
    </item>
    
    <item>
      <title>kubernetes中pod同步时区问题</title>
      <link>https://blog.maoxianplay.com/2019/pod-timezone/</link>
      <pubDate>Wed, 30 Jan 2019 20:18:13 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2019/pod-timezone/</guid>
      <description>  新版监控大屏于18年最后一天正式上线，之后陆续进行了几次优化和修改，最近发现一个比较大的bug，就是监控显示的时间轴不对，显示的就是和目前的时间相差8小时，这就引出了docker中的时区问题
 问题的原因 默认的情况，在K8S里启动一个容器，该容器的设置的时区是UTC0，但是对用户而言，主机环境并不在UTC0。我们在UTC8。如果不把容器的时区和主机主机设置为一致，则在查找日志等时候将非常不方便，也容易造成误解。但是K8S以及Docker容器没有一个简便的设置/开关在系统层面做配置。都需要我们从单个容器入手做设置，具体有两个方法：
 直接修改镜像的时间设置，好处是应用部署时无需做特殊设置，但是需要手动构建Docker镜像。 部署应用时，单独读取主机的“/etc/localtime”文件，即创建pod时同步时区，无需修改镜像，但是每个应用都要单独设置。  问题的解决 这里我们选择第二种方法，即修改部署应用的yaml文件，创建pod时同步时区
apiVersion: extensions/v1beta1 kind: Deployment metadata: name: myweb spec: replicas: 2 template: metadata: labels: app: myweb spec: containers: - name: myweb image: nginx:apline ports: - containerPort: 80 #挂载到pod中 volumeMounts: - name: host-time mountPath: /etc/localtime #需要被挂载的宿主机的时区文件 volumes: - name: host-time hostPath: path: /etc/localtime  效果对比 修改时区前 修改时区后 </description>
    </item>
    
    <item>
      <title>为ingress配置SSL证书，实现HTTPS访问</title>
      <link>https://blog.maoxianplay.com/2018/https-ingress/</link>
      <pubDate>Sat, 29 Dec 2018 21:28:13 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/https-ingress/</guid>
      <description>devops平台率先在公司内使用kubernetes集群提供后端服务，但是由于之前一直处于探索阶段，所以使用的事http的方式提供后端服务，但是在开发统一入口后，出现了访问HTTPS页面的跨域问题，由此引出了后端服务配置SSL证书的问题
 使用rancher配置SSL证书 下载SSL证书文件 首先需要获得SSL证书文件，可以直接在阿里云SSL证书管理控制台下载
选中需要下载证书，选择下载nginx证书 将证书上传项目 打开rancher，选择要使用证书的项目，点击资源中的证书
将证书上传项目 打开rancher，选择要使用证书的项目，点击资源中的证书 添加证书，点击从文件上传 上传证书文件中的秘钥和证书，点击保存即可
使用yaml上传证书 这个证书的原理其实是在相应的命名空间创建了一个包含证书信息的secrets
apiVersion: v1 data: tls.crt: {私钥} tls.key: {证书} kind: Secret metadata: name: keking-cn namespace: devops-plat type: kubernetes.io/tls  在kubernetes上运行该yaml即可
rancher中证书绑定 选中需要绑定证书的ingress，点击编辑，选中证书，保存即可（由于ingress-controller中没有绑定默认证书，所以这里不能选中默认） 保存完毕，证书即可生效</description>
    </item>
    
    <item>
      <title>阿里云部署rancher2.1采坑记</title>
      <link>https://blog.maoxianplay.com/2018/install-rancher/</link>
      <pubDate>Thu, 29 Nov 2018 18:28:13 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/install-rancher/</guid>
      <description>近期由于公司需要将部署在ucloud上的rancher迁移到阿里云上，所以将部署到阿里云的图中遇到的问题和踩到的坑在这里进行记录
 无法删除namespace 在安装新环境的rancher之前，需要将kubernetes集群中cattle-system ns下面的cluster-agent和node-agent干掉，这里我选择直接删除cattle-system这个命名空间
kubectl delete ns cattle-system  然而问题来了，在删除命名空间之后，这个命名空间并没有立刻被删除，而是一直处于Terminating状态，这里我专门写了一篇文章解决这个问题，这里就不再赘述
阿里云证书配置 由于之前使用的ucloud的机器进行测试，使用默认自签名证书并没有使用SSL证书，所以在配置证书这里遇到的许多的问题
首先根据官方文档使用权威CA机构颁发的证书，这里使用的是本公司自己的证书
获取证书方法： 点击下载证书，选择nginx证书下载 之后将下载的证书上传到rancher所在服务器，并配置好数据卷挂载
将下面代码的挂载地址指向证书文件，运行代码
docker run -d --restart=unless-stopped \ -p 80:80 -p 443:443 \ -v /root/var/log/auditlog:/var/log/auditlog \ -e AUDIT_LEVEL=3 \ -v /etc/your_certificate_directory/fullchain.pem:/etc/rancher/ssl/cert.pem \ -v /etc/your_certificate_directory/privkey.pem:/etc/rancher/ssl/key.pem \ rancher/rancher:latest --no-cacerts  之后会自动冲dockerhub上拉取最新的rancher进行进行安装，之后使用命令
docker ps  查看容器是否在运行，如果运行正常，则后端的配置就完成了
划重点：这是是在后端配置了证书，所以在阿里云的配置上要使用四层TCP监听
这个地方可是坑了我许久，我一直在前端配置https七层监听，导致一直无法正常访问，一度已经到了怀疑人生的地步=。=
之后就是简单的阿里云SLB配置四层TCP监听，这里也就不再赘述了
k8s集群导入rancher 前后端都准备就绪，现在就可以访问rancher了，访问rancher根据页面提示进行基本配置，登录后选择添加集群
选择导入现有集群 为集群创建一个rancher中的名称，然后根据提示将命令拷贝到k8s集群所在宿主机执行即可，注意：这里由于配置了证书，所以选择有证书，不绕过证书的那个命令执行，之后就可看到集群数据导入中 等待几秒即可开心的使用rancher了！
关于rancher部署后访问集群api超时问题 经过排查，原因是阿里云在容器服务对外连接处设置了TLS双向认证，导致rancher的外网ip经常性的被拦截，导致超时
解决办法：
对k8s集群中rancher的cattle-cluster-agent传递内网参数，将其配置为内网连接，就可以正常访问了
kubectl -n cattle-system patch deployments cattle-cluster-agent --patch &#39;{ &amp;quot;spec&amp;quot;: { &amp;quot;template&amp;quot;: { &amp;quot;spec&amp;quot;: { &amp;quot;hostAliases&amp;quot;: [{ &amp;quot;hostnames&amp;quot;:[&amp;quot;rancher.</description>
    </item>
    
    <item>
      <title>Kubernetes删除一直处于Terminating状态的namespace</title>
      <link>https://blog.maoxianplay.com/2018/k8s-d-n/</link>
      <pubDate>Fri, 16 Nov 2018 18:18:13 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/k8s-d-n/</guid>
      <description>  近期由于公司需要将部署在ucloud上的rancher迁移到阿里云上，所以需要将原有Rancher依赖的namespace（cattle-system）删除，但在删除中出现了删除的namespace一直处于Terminating状态的情况  解决方案 运行命令：
kubectl edit namespaces cattle-system  可以看到namespaces的yaml配置： 将finalizer的value删除，这里将其设置为[]
保存即可看到该namespace已被删除 </description>
    </item>
    
    <item>
      <title>阿里云日志服务采集k8s日志并实现livetail功能</title>
      <link>https://blog.maoxianplay.com/2018/dashboard-k8s/</link>
      <pubDate>Mon, 29 Oct 2018 21:28:13 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/dashboard-k8s/</guid>
      <description>前言  目前的项目日志都是通过Logtail直接采集，投递到OSS持久化，同时可以通过阿里云日志服务、devops自建平台进行查看（虽然大部分人是直接登录ECS查看=。=）， 在开始进行容器化之后，同样遇到日志的问题，目前的解决方案是阿里云日志服务持久化和展现格式化后的日志、使用rancher查看实时日志， 但是之前由于rancher平台出现一些问题，导致不能及时查看日志的情况，在这个背景下对阿里云日志服务采集k8s日志和livetail进行搭建并调研词方案是否可行。
 简介（转自阿里云官方文档） 日志服务（Log Service，简称 LOG）是针对日志类数据的一站式服务，在阿里巴巴集团经历大量大数据场景锤炼而成。您无需开发就能快捷完成日志数据采集、消费、投递以及查询分析等功能，提升运维、运营效率，建立 DT 时代海量日志处理能力。
kubernetes日志采集组件安装 安装Logtail  进入阿里云容器服务找到集群id  通过ssh登录master节点，或者任意安装了kubectl并配置了该集群kubeconfig的服务器
 执行命令，将${your_k8s_cluster_id}替换为集群id
wget http://logtail-release-cn-hangzhou.oss-cn-hangzhou.aliyuncs.com/kubernetes/alicloud-log-k8s-install.sh -O alicloud-log-k8s-install.sh; chmod 744 ./alicloud-log-k8s-install.sh; sh ./alicloud-log-k8s-install.sh ${your_k8s_cluster_id}   Project k8s-log-${your_k8s_cluster_id}下会自动创建名为config-operation-log的Logstore，用于存储alibaba-log-controller的运行日志。请勿删除此Logstore，否则无法为alibaba-log-controller排查问题。 若您需要将日志采集到已有的Project，请执行安装命令sh ./alicloud-log-k8s-install.sh${your_k8s_cluster_id} ${your_project_name} ，并确保日志服务Project和您的Kubernetes集群在同一地域。  该条命令其实就是执行了一个shell脚本，使用helm安装了采集kubernetes集群日志的组件
#!/bin/bash if [ $# -eq 0 ] ; then echo &amp;quot;[Invalid Param], use sudo ./install-k8s-log.sh {your-k8s-cluster-id}&amp;quot; exit 1 fi clusterName=$(echo $1 | tr &#39;[A-Z]&#39; &#39;[a-z]&#39;) curl --connect-timeout 5 http://100.100.100.200/latest/meta-data/region-id if [ $?</description>
    </item>
    
    <item>
      <title>kubernetes集群概述</title>
      <link>https://blog.maoxianplay.com/2018/k8s-topo/</link>
      <pubDate>Wed, 03 Oct 2018 12:18:13 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/k8s-topo/</guid>
      <description>  随着2017年AWS，Azure和阿里云相继在其原有容器服务上新增了对kubernetes的支持，而Docker官网也在同年10月宣布同时支持Swarm好kubernetes容器编排系统。kubernetes俨然已成为容器编排领域事实上的标准，而2018年更是各大公司相继将服务迁移到kubernetes上，而kubernetes则以惊人更新速度，保持着每个季度发布一个大版本的速度高速发展着。
 kubernetes特征 kubernetes是一种在一组主机上运行和协同容器化应用程序的系统，旨在提供可预测性、可拓展性与高可用性的方法来完全管理容器化应用和服务的生命周期平台。用户可以定义应用程序的运行方式，以及与其他应用程序或外部世界交互的途径，并能实现服务的扩容和缩容，执行平滑滚动更新，以及在不同版本的应用程序之间调度流量以测试功能或回滚有问题的部署。kubernetes提供了接口和可组合帆软平台原语，使得用户能够以高度的灵活性和可靠性定义及管理应用程序。
kubernetes组件及网络通信 kubernetes集群的客户端可以分为两类：API Server客户端和应用程序（运行为Pod中的容器）客户端。  第一类客户端通常包含用户和Pod对象两种，它们通过API Server访问kubernetes集群完成管理任务，例如，管理集群上的各种资源对象。 第二类客户端一般也包含人类用户和Pod对象两种，它们的访问目标是Pod上运行于容器中的应用程序提供的各种具体的服务，如redis或nginx等，不过，这些访问请求通常要经由Service或Ingress资源对象进行。另外，第二类客户端的访问目标对象的操作要经由第一类客户端创建和配置完成后才进行。
访问API Server时，人类用户一般借助于命令行工具kubectl或图形UI（例如kubernetes dashboard）进行，也通过编程接口进行访问，包括REST API。访问Pod中的应用时，其访问方式要取决于Pod中的应用程序，例如，对于运行Nginx容器的Pod来说，其最常用工具就是浏览器。
管理员（开发人员或运维人员）使用kubernetes集群的常见操作包括通过控制器创建Pod，在Pod的基础上创建Service供第二类客户端访问，更新Pod中的应用版本（更新和回滚）以及对应用规模进行扩容或缩容等，另外还有集群附件管理、存储卷管理、网络及网络策略管理、资源管理和安全管理等。
  </description>
    </item>
    
    <item>
      <title>精简docker镜像</title>
      <link>https://blog.maoxianplay.com/2018/image-size/</link>
      <pubDate>Thu, 27 Sep 2018 20:28:13 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/image-size/</guid>
      <description>精简Docker镜像的好处很多，不仅可以节省存储空间和带宽，还能减少安全隐患。优化镜像大小的手段多种多样，因服务所使用的基础开发语言不同而有差异。本文将介绍精简Docker镜像的几种通用方法。
 精简Docker镜像大小的必要性 Docker镜像由很多镜像层（Layers）组成（最多127层），镜像层依赖于一系列的底层技术，比如文件系统(filesystems)、写时复制(copy-on-write)、联合挂载(union mounts)等技术，你可以查看Docker社区文档以了解更多有关Docker存储驱动的内容，这里就不再赘述技术细节。总的来说，Dockerfile中的每条指令都会创建一个镜像层，继而会增加整体镜像的尺寸。
下面是精简Docker镜像尺寸的好处：
 减少构建时间 减少磁盘使用量 减少下载时间 因为包含文件少，攻击面减小，提高了安全性 提高部署速度  五点建议减小Docker镜像尺寸
一、优化基础镜像 优化基础镜像的方法就是选用合适的更小的基础镜像，常用的 Linux 系统镜像一般有 Ubuntu、CentOs、Alpine，其中Alpine更推荐使用。大小对比如下：
guoxudong@ubuntu ~/s&amp;gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 74f8760a2a8b 8 days ago 82.4MB alpine latest 11cd0b38bc3c 2 weeks ago 4.41MB centos 7 49f7960eb7e4 7 weeks ago 200MB debian latest 3bbb526d2608 8 days ago 101MB guoxudong@ubuntu ~/s&amp;gt;  Alpine是一个高度精简又包含了基本工具的轻量级Linux发行版，基础镜像只有4.41M，各开发语言和框架都有基于Alpine制作的基础镜像，强烈推荐使用它。Alpine镜像各个语言和框架支持情况，可以参考《优化Docker镜像、加速应用部署》。 查看上面的镜像尺寸对比结果，你会发现最小的镜像也有4.41M，那么有办法构建更小的镜像吗？答案是肯定的，例如 gcr.io/google_containers/pause-amd64:3.1 镜像仅有742KB。为什么这个镜像能这么小？在为大家解密之前，再推荐两个基础镜像：
 scratch镜像  scratch是一个空镜像，只能用于构建其他镜像，比如你要运行一个包含所有依赖的二进制文件，如Golang程序，可以直接使用scratch作为基础镜像。现在给大家展示一下上文提到的Google pause镜像Dockerfile：</description>
    </item>
    
    <item>
      <title>Docker容器启动退出解决方案</title>
      <link>https://blog.maoxianplay.com/2018/docker-quit/</link>
      <pubDate>Thu, 27 Sep 2018 19:27:03 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/docker-quit/</guid>
      <description>现象 启动docker容器
docker run –name [CONTAINER_NAME] [CONTAINER_ID]  查看容器运行状态
docker ps -a  发现刚刚启动的mydocker容器已经退出
原因 docker容器的主线程（dockfile中CMD执行的命令）结束，容器会退出
解决办法  可以使用交互式启动
docker run -i [CONTAINER_NAME or CONTAINER_ID]  上面的不太友好，建议使用后台模式和tty选项
docker run -dit [CONTAINER_NAME or CONTAINER_ID]  Docker 容器在后台以守护态（Daemonized）形式运行，可以通过添加 -d 参数来实现
$ sudo docker run -d ubuntu:14.04 /bin/sh -c &amp;quot;while true; do echo hello world; sleep 1; done&amp;quot;  在脚本最后一行添加tail -f /dev/null，这个命令永远完成不了，所以该脚本一直不会执行完，所以该容器永远不会退出。
   TIPs:退出时，使用[ctrl + D]，这样会结束docker当前线程，容器结束，可以使用[ctrl + P][ctrl + Q]退出而不终止容器运行</description>
    </item>
    
    <item>
      <title>容器技术概述</title>
      <link>https://blog.maoxianplay.com/2018/con-ind/</link>
      <pubDate>Thu, 30 Aug 2018 18:45:22 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/con-ind/</guid>
      <description> 背景  自从微服务（Microservice）的出现，出于业务的需要，IT应用模型不断的变革。开发模式从瀑布式到敏捷开发；开发、运维和测试互相配合的devops思想；应用程序架构从单体模型到分层模型再到微服务；部署方式也从面向物理机到虚拟键再到容器；应用程序的基础架构从自建机房到托管再到云计算，等等。这些变革使得IT技术应用的效率大大提升，同时却以更低的成本交付更高质量的产品。
尤其是以Docker为代表的容器技术的出现，终结了devops中交付和部署环节因环节、配置及程序本身的不同而造成的动辄几种甚至十几种部署配置的困境，将它们统一在容器镜像（image）之上。这就是我在工作中遇到最先遇到的困境，同时也是我开始研究容器技术的契机。
如今，越来越多的企业或组织开始开始选择以镜像文件为交付载体。容器镜像之内直接包含了应用程序及其依赖的系统环境、库、基础程序等，从而能够在容器引擎上直接运行。
 容器技术概述 容器是一种轻量级、可移植、自包含的软件打包技术，它使得应用程序可以在几乎任何地方以相同的方式运行。
容器有应用程序本身和它的环境依赖（库和其他应用程序）两部分组成，并在宿主机（Host）操作系统的用户空间中运行，但与操作系统的其他进程互相隔离，他们的实现机制有别于VMWare、KVM、Xen等实现方案的虚拟化技术。容器与虚拟机的对比关系如下图 由于同一个宿主机上的所有容器都共享其底层操作系统（内核空间），这就使得容器在体积上要比传统的虚拟机小很多。另外，启动容器无须启动整个操作系统，所以容器部署和启动的速度更快，开销更小，也更容易迁移。事实上，容器赋予了应用程序超强的可移植能力。
容器技术的优势  开发方面：“一次构建、到处运行”（Build Once, Run Anywhere）。容器意味着环境隔离和可重复性，开发人员只需为应用创建一个运行环境，并将其打包成容器便可在各种部署环境上运行，并与它所在的宿主机环境隔离。 运维方面：“一次配置，运行所以”（Configure Once, Run Anything）。一旦配置好标准的容器运行时环境，服务器就可以运行任何容器，这使得运维人员的工作变得更高效、一致和可重复。容器消除了开发、测试、生产环境的不一致性。  </description>
    </item>
    
    <item>
      <title>centos7.2 安装k8s v1.11.0</title>
      <link>https://blog.maoxianplay.com/2018/install-k8s/</link>
      <pubDate>Tue, 14 Aug 2018 20:07:03 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/install-k8s/</guid>
      <description>前言  最近由于公司业务发展到了瓶颈，原有的技术架构已经逐渐无法满足业务开发和测试的需求，出现了应用测试环境搭建复杂，有许多套（真的很多很多）应用环境，应用在持续集成/持续交付也遇到了很大的困难，经过讨论研究决定对应用和微服务进行容器化，这就是我首次直面docker和k8s的契机（好吧，我是菜鸟）
 Kubernetes 介绍 Kubernetes 是 Google 团队发起的开源项目，它的目标是管理跨多个主机的容器，提供基本的部署，维护以及运用伸缩，主要实现语言为 Go 语言。 Kubernetes的特点：
 易学：轻量级，简单，容易理解 便携：支持公有云，私有云，混合云，以及多种云平台 可拓展：模块化，可插拔，支持钩子，可任意组合 自修复：自动重调度，自动重启，自动复制  准备工作 注：以下操作都是在root权限下执行的
 安装docker-ce，这里使用docker-ce-17.09.0.c版本，安装方法见之前的教程 安装Kubeadm
#安装 Kubeadm 首先我们要配置好阿里云的国内源，执行如下命令： cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 EOF #之后，执行以下命令来重建yum缓存： yum -y install epel-releaseyum clean all yum makecache  接下来需要安装指定版本的Kubeadm（这里要安装指定版本，因为后续依赖的镜像由于有墙无法拉取，这里我们只有指定版本的镜像），注意：这里是安装指定版本的Kubeadm，k8s的版本更新之快完全超出你的想象！
yum -y install kubelet-1.11.0-0 yum -y install kubeadm-1.11.0-0 yum -y install kubectl-1.11.0-0 yum -y install kubernetes-cni #执行命令启动Kubeadm服务： systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet  配置 Kubeadm 所用到的镜像 这里是重中之重，因为在国内的原因，无法访问到 Google 的镜像库，所以我们需要执行以下脚本来从 Docker Hub 仓库中获取相同的镜像，并且更改 TAG 让其变成与 Google 拉去镜像一致。</description>
    </item>
    
    <item>
      <title>centos7安装指定版本的docker</title>
      <link>https://blog.maoxianplay.com/2018/install-docker/</link>
      <pubDate>Tue, 14 Aug 2018 20:05:21 +0800</pubDate>
      
      <guid>https://blog.maoxianplay.com/2018/install-docker/</guid>
      <description>前言  在使用centos7，并使用荫安装搬运工的时候，往往不希望安装最新版本的搬运工，而是希望安装与自己熟悉或者当前业务环境需要的版本，例如目前Kubernetes支持的最新搬运工版本为v17.03，所以就产生了安装指定版本码头工人的需求。
 安装步骤 # 安装依赖包 yum install -y yum-utils device-mapper-persistent-data lvm2 # 添加Docker软件包源 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #关闭测试版本list（只显示稳定版） sudo yum-config-manager --enable docker-ce-edge sudo yum-config-manager --enable docker-ce-test # 更新yum包索引 yum makecache fast #NO.1 直接安装Docker CE （will always install the highest possible version，可能不符合你的需求） yum install docker-ce #NO.2 指定版本安装 yum list docker-ce --showduplicates|sort -r #找到需要安装的 yum install docker-ce-17.09.0.ce -y #启动docker systemctl start docker &amp;amp; systemctl enable docker  采坑指南  当然本着万事皆有坑的原则，这里也是有坑的，在安装中也是会遇到如下的问题</description>
    </item>
    
  </channel>
</rss>